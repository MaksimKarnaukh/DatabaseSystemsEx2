{
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "collapsed_sections": [
    "yFiHYiCYxOi1",
    "bdOqSfcgXTZv"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise: Create your own database using a compressed binary file"
   ],
   "metadata": {
    "id": "seu5hxlLwkuS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Fake Data File"
   ],
   "metadata": {
    "id": "yFiHYiCYxOi1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install Faker"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wb1_GWVxwgBR",
    "outputId": "4013c08e-dbd9-4105-9fdf-c060b3923131",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:39.740200Z",
     "iopub.execute_input": "2023-10-25T22:44:39.740616Z",
     "iopub.status.idle": "2023-10-25T22:44:49.760641Z",
     "shell.execute_reply.started": "2023-10-25T22:44:39.740583Z",
     "shell.execute_reply": "2023-10-25T22:44:49.759329Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:04.578662800Z",
     "start_time": "2023-12-03T13:49:03.658118400Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Faker in c:\\users\\maksim\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (20.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in c:\\users\\maksim\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maksim\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.4->Faker) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Maksim\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#create 1000.0000 users file\n",
    "\n",
    "user_columns = ['id','name','email','phone','company','street','street_number', 'zipcode','country','birthdate','deleted']\n",
    "\n",
    "#User storage: name:\n",
    "#id, street_number: 8 bytes (2 x 32 bitnumbers between 0 and 2^31)\n",
    "#name','email','phone','company','street','zipcode','country: strings of n characters requires n bytes: e.g. +-100 bytes\n",
    "def generate_data(size):\n",
    "  users = []\n",
    "  fake = Faker()\n",
    "  for i in range(0,size):\n",
    "    user = [i, fake.name(), fake.ascii_email(), fake.basic_phone_number(), fake.company(), fake.street_name(), random.randint(1,1000), fake.zipcode(), fake.country(), f'{random.randint(1970,2005)}-{random.randint(1,12)}-{random.randint(1,28)}', 0]\n",
    "    users.append(user)\n",
    "  df = pd.DataFrame(users,columns=user_columns)\n",
    "  return df\n",
    "\n",
    "size = 10000\n",
    "df = generate_data(size) #Takes about 1 minutes to run or about 12 minutes for 1000000 rows\n",
    "display(df)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "1w7wIfCixYCU",
    "outputId": "9b188903-e2ba-4e14-f11d-95c57a710ccc",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:49.762617Z",
     "iopub.execute_input": "2023-10-25T22:44:49.763017Z",
     "iopub.status.idle": "2023-10-25T22:44:57.809247Z",
     "shell.execute_reply.started": "2023-10-25T22:44:49.762943Z",
     "shell.execute_reply": "2023-10-25T22:44:57.807544Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:07.652079800Z",
     "start_time": "2023-12-03T13:49:04.578662800Z"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "        id               name                                 email  \\\n0        0     Patricia Smith                 eriksmith@hotmail.com   \n1        1     Kenneth George            walterswhitney@hotmail.com   \n2        2   Christine Harris                  yferguson@hudson.com   \n3        3      Alison Dennis                  jonathan83@gmail.com   \n4        4  Stephanie Wilkins              kevinchavez@williams.biz   \n...    ...                ...                                   ...   \n9995  9995     Heather Moreno  shannonsanchez@thompson-thompson.com   \n9996  9996     Jose Henderson                      kgreen@gmail.com   \n9997  9997         Kari Jones             donna83@adams-johnson.org   \n9998  9998        Denise Cook        lanesamantha@carney-doyle.info   \n9999  9999       Walter Smith                   fpotter@hotmail.com   \n\n              phone                    company           street  \\\n0        7326407883               Wells-Mendez      Julie Creek   \n1      362-637-0162             Jones and Sons     Denise Walks   \n2     (748)937-3676                  Adams PLC    Michael Ferry   \n3     (856)251-1000  Gomez, Holloway and Dixon     Wood Squares   \n4      563-847-5604    Atkinson, Lee and Singh   Friedman Lakes   \n...             ...                        ...              ...   \n9995  (902)326-9417             Jones and Sons    Heather Ville   \n9996   588-943-1228                Jones-Lewis  Daniel Crossing   \n9997     3098697653    Lamb, Cummings and Dunn     King Highway   \n9998  (636)382-0743                  Floyd Ltd       Watson Way   \n9999  (307)925-0245             Sampson-Torres     Jenna Stream   \n\n      street_number zipcode  \\\n0               604   51907   \n1               141   10459   \n2                61   17092   \n3               994   75845   \n4               715   69102   \n...             ...     ...   \n9995            741   40316   \n9996             26   95087   \n9997            859   49790   \n9998            147   26443   \n9999            671   31158   \n\n                                                country  birthdate  deleted  \n0                           Falkland Islands (Malvinas)  1982-1-12        0  \n1                                                Bhutan   1976-6-1        0  \n2                                                 Italy  1973-7-16        0  \n3                                              Botswana  1979-8-25        0  \n4                                          South Africa  1984-12-8        0  \n...                                                 ...        ...      ...  \n9995                                              Ghana  1995-1-15        0  \n9996                                   Saint Barthelemy  1984-9-21        0  \n9997  British Indian Ocean Territory (Chagos Archipe...   1983-8-9        0  \n9998                                              China  1992-5-15        0  \n9999                                            Andorra   1981-1-2        0  \n\n[10000 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>email</th>\n      <th>phone</th>\n      <th>company</th>\n      <th>street</th>\n      <th>street_number</th>\n      <th>zipcode</th>\n      <th>country</th>\n      <th>birthdate</th>\n      <th>deleted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Patricia Smith</td>\n      <td>eriksmith@hotmail.com</td>\n      <td>7326407883</td>\n      <td>Wells-Mendez</td>\n      <td>Julie Creek</td>\n      <td>604</td>\n      <td>51907</td>\n      <td>Falkland Islands (Malvinas)</td>\n      <td>1982-1-12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Kenneth George</td>\n      <td>walterswhitney@hotmail.com</td>\n      <td>362-637-0162</td>\n      <td>Jones and Sons</td>\n      <td>Denise Walks</td>\n      <td>141</td>\n      <td>10459</td>\n      <td>Bhutan</td>\n      <td>1976-6-1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Christine Harris</td>\n      <td>yferguson@hudson.com</td>\n      <td>(748)937-3676</td>\n      <td>Adams PLC</td>\n      <td>Michael Ferry</td>\n      <td>61</td>\n      <td>17092</td>\n      <td>Italy</td>\n      <td>1973-7-16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Alison Dennis</td>\n      <td>jonathan83@gmail.com</td>\n      <td>(856)251-1000</td>\n      <td>Gomez, Holloway and Dixon</td>\n      <td>Wood Squares</td>\n      <td>994</td>\n      <td>75845</td>\n      <td>Botswana</td>\n      <td>1979-8-25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Stephanie Wilkins</td>\n      <td>kevinchavez@williams.biz</td>\n      <td>563-847-5604</td>\n      <td>Atkinson, Lee and Singh</td>\n      <td>Friedman Lakes</td>\n      <td>715</td>\n      <td>69102</td>\n      <td>South Africa</td>\n      <td>1984-12-8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>9995</td>\n      <td>Heather Moreno</td>\n      <td>shannonsanchez@thompson-thompson.com</td>\n      <td>(902)326-9417</td>\n      <td>Jones and Sons</td>\n      <td>Heather Ville</td>\n      <td>741</td>\n      <td>40316</td>\n      <td>Ghana</td>\n      <td>1995-1-15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>9996</td>\n      <td>Jose Henderson</td>\n      <td>kgreen@gmail.com</td>\n      <td>588-943-1228</td>\n      <td>Jones-Lewis</td>\n      <td>Daniel Crossing</td>\n      <td>26</td>\n      <td>95087</td>\n      <td>Saint Barthelemy</td>\n      <td>1984-9-21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>9997</td>\n      <td>Kari Jones</td>\n      <td>donna83@adams-johnson.org</td>\n      <td>3098697653</td>\n      <td>Lamb, Cummings and Dunn</td>\n      <td>King Highway</td>\n      <td>859</td>\n      <td>49790</td>\n      <td>British Indian Ocean Territory (Chagos Archipe...</td>\n      <td>1983-8-9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>9998</td>\n      <td>Denise Cook</td>\n      <td>lanesamantha@carney-doyle.info</td>\n      <td>(636)382-0743</td>\n      <td>Floyd Ltd</td>\n      <td>Watson Way</td>\n      <td>147</td>\n      <td>26443</td>\n      <td>China</td>\n      <td>1992-5-15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>9999</td>\n      <td>Walter Smith</td>\n      <td>fpotter@hotmail.com</td>\n      <td>(307)925-0245</td>\n      <td>Sampson-Torres</td>\n      <td>Jenna Stream</td>\n      <td>671</td>\n      <td>31158</td>\n      <td>Andorra</td>\n      <td>1981-1-2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save and load CSV file"
   ],
   "metadata": {
    "id": "bdOqSfcgXTZv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "fname = 'fake_users.csv'\n",
    "df.to_csv(fname, index=False)\n",
    "file_size = os.stat(fname).st_size\n",
    "print(f\"CSV file size is {file_size}B. Elapsed: {time.time()-start}s\")\n",
    "#File Size in Bytes is 1182617 (or on average 120 bytes per record) in csv.\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b64l181SXMYJ",
    "outputId": "63ddf457-7f9a-4c78-cd5d-de5d8fdf5023",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:57.810554Z",
     "iopub.execute_input": "2023-10-25T22:44:57.810885Z",
     "iopub.status.idle": "2023-10-25T22:44:57.884915Z",
     "shell.execute_reply.started": "2023-10-25T22:44:57.810854Z",
     "shell.execute_reply": "2023-10-25T22:44:57.883901Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:07.712648700Z",
     "start_time": "2023-12-03T13:49:07.651079300Z"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file size is 1211400B. Elapsed: 0.01886916160583496s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "start = time.time()\n",
    "df = pd.read_csv('fake_users.csv')\n",
    "print(f\"Loading CSV. Elapsed: {time.time()-start}s\")\n",
    "display(df)\n",
    "display(df.describe(include='all'))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "id": "RUyq8P-W6Ubw",
    "outputId": "084b7078-783c-497e-9fda-8d994f1d3e32",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:57.887207Z",
     "iopub.execute_input": "2023-10-25T22:44:57.887516Z",
     "iopub.status.idle": "2023-10-25T22:44:58.010500Z",
     "shell.execute_reply.started": "2023-10-25T22:44:57.887491Z",
     "shell.execute_reply": "2023-10-25T22:44:58.008909Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:07.822299500Z",
     "start_time": "2023-12-03T13:49:07.684055700Z"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV. Elapsed: 0.025174856185913086s\n"
     ]
    },
    {
     "data": {
      "text/plain": "        id               name                                 email  \\\n0        0     Patricia Smith                 eriksmith@hotmail.com   \n1        1     Kenneth George            walterswhitney@hotmail.com   \n2        2   Christine Harris                  yferguson@hudson.com   \n3        3      Alison Dennis                  jonathan83@gmail.com   \n4        4  Stephanie Wilkins              kevinchavez@williams.biz   \n...    ...                ...                                   ...   \n9995  9995     Heather Moreno  shannonsanchez@thompson-thompson.com   \n9996  9996     Jose Henderson                      kgreen@gmail.com   \n9997  9997         Kari Jones             donna83@adams-johnson.org   \n9998  9998        Denise Cook        lanesamantha@carney-doyle.info   \n9999  9999       Walter Smith                   fpotter@hotmail.com   \n\n              phone                    company           street  \\\n0        7326407883               Wells-Mendez      Julie Creek   \n1      362-637-0162             Jones and Sons     Denise Walks   \n2     (748)937-3676                  Adams PLC    Michael Ferry   \n3     (856)251-1000  Gomez, Holloway and Dixon     Wood Squares   \n4      563-847-5604    Atkinson, Lee and Singh   Friedman Lakes   \n...             ...                        ...              ...   \n9995  (902)326-9417             Jones and Sons    Heather Ville   \n9996   588-943-1228                Jones-Lewis  Daniel Crossing   \n9997     3098697653    Lamb, Cummings and Dunn     King Highway   \n9998  (636)382-0743                  Floyd Ltd       Watson Way   \n9999  (307)925-0245             Sampson-Torres     Jenna Stream   \n\n      street_number  zipcode  \\\n0               604    51907   \n1               141    10459   \n2                61    17092   \n3               994    75845   \n4               715    69102   \n...             ...      ...   \n9995            741    40316   \n9996             26    95087   \n9997            859    49790   \n9998            147    26443   \n9999            671    31158   \n\n                                                country  birthdate  deleted  \n0                           Falkland Islands (Malvinas)  1982-1-12        0  \n1                                                Bhutan   1976-6-1        0  \n2                                                 Italy  1973-7-16        0  \n3                                              Botswana  1979-8-25        0  \n4                                          South Africa  1984-12-8        0  \n...                                                 ...        ...      ...  \n9995                                              Ghana  1995-1-15        0  \n9996                                   Saint Barthelemy  1984-9-21        0  \n9997  British Indian Ocean Territory (Chagos Archipe...   1983-8-9        0  \n9998                                              China  1992-5-15        0  \n9999                                            Andorra   1981-1-2        0  \n\n[10000 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>email</th>\n      <th>phone</th>\n      <th>company</th>\n      <th>street</th>\n      <th>street_number</th>\n      <th>zipcode</th>\n      <th>country</th>\n      <th>birthdate</th>\n      <th>deleted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Patricia Smith</td>\n      <td>eriksmith@hotmail.com</td>\n      <td>7326407883</td>\n      <td>Wells-Mendez</td>\n      <td>Julie Creek</td>\n      <td>604</td>\n      <td>51907</td>\n      <td>Falkland Islands (Malvinas)</td>\n      <td>1982-1-12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Kenneth George</td>\n      <td>walterswhitney@hotmail.com</td>\n      <td>362-637-0162</td>\n      <td>Jones and Sons</td>\n      <td>Denise Walks</td>\n      <td>141</td>\n      <td>10459</td>\n      <td>Bhutan</td>\n      <td>1976-6-1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Christine Harris</td>\n      <td>yferguson@hudson.com</td>\n      <td>(748)937-3676</td>\n      <td>Adams PLC</td>\n      <td>Michael Ferry</td>\n      <td>61</td>\n      <td>17092</td>\n      <td>Italy</td>\n      <td>1973-7-16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Alison Dennis</td>\n      <td>jonathan83@gmail.com</td>\n      <td>(856)251-1000</td>\n      <td>Gomez, Holloway and Dixon</td>\n      <td>Wood Squares</td>\n      <td>994</td>\n      <td>75845</td>\n      <td>Botswana</td>\n      <td>1979-8-25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Stephanie Wilkins</td>\n      <td>kevinchavez@williams.biz</td>\n      <td>563-847-5604</td>\n      <td>Atkinson, Lee and Singh</td>\n      <td>Friedman Lakes</td>\n      <td>715</td>\n      <td>69102</td>\n      <td>South Africa</td>\n      <td>1984-12-8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>9995</td>\n      <td>Heather Moreno</td>\n      <td>shannonsanchez@thompson-thompson.com</td>\n      <td>(902)326-9417</td>\n      <td>Jones and Sons</td>\n      <td>Heather Ville</td>\n      <td>741</td>\n      <td>40316</td>\n      <td>Ghana</td>\n      <td>1995-1-15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>9996</td>\n      <td>Jose Henderson</td>\n      <td>kgreen@gmail.com</td>\n      <td>588-943-1228</td>\n      <td>Jones-Lewis</td>\n      <td>Daniel Crossing</td>\n      <td>26</td>\n      <td>95087</td>\n      <td>Saint Barthelemy</td>\n      <td>1984-9-21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>9997</td>\n      <td>Kari Jones</td>\n      <td>donna83@adams-johnson.org</td>\n      <td>3098697653</td>\n      <td>Lamb, Cummings and Dunn</td>\n      <td>King Highway</td>\n      <td>859</td>\n      <td>49790</td>\n      <td>British Indian Ocean Territory (Chagos Archipe...</td>\n      <td>1983-8-9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>9998</td>\n      <td>Denise Cook</td>\n      <td>lanesamantha@carney-doyle.info</td>\n      <td>(636)382-0743</td>\n      <td>Floyd Ltd</td>\n      <td>Watson Way</td>\n      <td>147</td>\n      <td>26443</td>\n      <td>China</td>\n      <td>1992-5-15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>9999</td>\n      <td>Walter Smith</td>\n      <td>fpotter@hotmail.com</td>\n      <td>(307)925-0245</td>\n      <td>Sampson-Torres</td>\n      <td>Jenna Stream</td>\n      <td>671</td>\n      <td>31158</td>\n      <td>Andorra</td>\n      <td>1981-1-2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                 id              name                 email       phone  \\\ncount   10000.00000             10000                 10000       10000   \nunique          NaN              9382                  9946       10000   \ntop             NaN  Michael Williams  jennifer72@yahoo.com  7326407883   \nfreq            NaN                 7                     3           1   \nmean     4999.50000               NaN                   NaN         NaN   \nstd      2886.89568               NaN                   NaN         NaN   \nmin         0.00000               NaN                   NaN         NaN   \n25%      2499.75000               NaN                   NaN         NaN   \n50%      4999.50000               NaN                   NaN         NaN   \n75%      7499.25000               NaN                   NaN         NaN   \nmax      9999.00000               NaN                   NaN         NaN   \n\n            company            street  street_number       zipcode country  \\\ncount         10000             10000   10000.000000  10000.000000   10000   \nunique         8675              9470            NaN           NaN     243   \ntop     Johnson Ltd  Michael Turnpike            NaN           NaN   Congo   \nfreq             16                 4            NaN           NaN      87   \nmean            NaN               NaN     500.597900  50620.733900     NaN   \nstd             NaN               NaN     288.567411  28881.826391     NaN   \nmin             NaN               NaN       1.000000    519.000000     NaN   \n25%             NaN               NaN     249.000000  25863.500000     NaN   \n50%             NaN               NaN     501.000000  50582.500000     NaN   \n75%             NaN               NaN     752.000000  75878.500000     NaN   \nmax             NaN               NaN    1000.000000  99948.000000     NaN   \n\n        birthdate  deleted  \ncount       10000  10000.0  \nunique       6787      NaN  \ntop     2005-4-16      NaN  \nfreq            5      NaN  \nmean          NaN      0.0  \nstd           NaN      0.0  \nmin           NaN      0.0  \n25%           NaN      0.0  \n50%           NaN      0.0  \n75%           NaN      0.0  \nmax           NaN      0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>email</th>\n      <th>phone</th>\n      <th>company</th>\n      <th>street</th>\n      <th>street_number</th>\n      <th>zipcode</th>\n      <th>country</th>\n      <th>birthdate</th>\n      <th>deleted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10000.00000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000.0</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>9382</td>\n      <td>9946</td>\n      <td>10000</td>\n      <td>8675</td>\n      <td>9470</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>243</td>\n      <td>6787</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>Michael Williams</td>\n      <td>jennifer72@yahoo.com</td>\n      <td>7326407883</td>\n      <td>Johnson Ltd</td>\n      <td>Michael Turnpike</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Congo</td>\n      <td>2005-4-16</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>7</td>\n      <td>3</td>\n      <td>1</td>\n      <td>16</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>87</td>\n      <td>5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4999.50000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>500.597900</td>\n      <td>50620.733900</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2886.89568</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>288.567411</td>\n      <td>28881.826391</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.00000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>519.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2499.75000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>249.000000</td>\n      <td>25863.500000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4999.50000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>501.000000</td>\n      <td>50582.500000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7499.25000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>752.000000</td>\n      <td>75878.500000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9999.00000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1000.000000</td>\n      <td>99948.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#get some stats required for encoding, such as length of faker strings\n",
    "for col in df.columns:\n",
    "  if pd.api.types.is_int64_dtype(df[col].iloc[0]):\n",
    "    print(f'col {col} is integer. range: {df[col].min()}-{df[col].max()}. unique: {df[col].nunique()}')\n",
    "  elif isinstance(df[col].iloc[0],str):\n",
    "    print(f'col {col} is string. range: {df[col].apply(len).min()}-{df[col].apply(len).max()}. unique: {df[col].nunique()}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXekqe3KRiC1",
    "outputId": "9788cbd3-7b9a-4ff3-c0d8-72aaee4628c9",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:58.013631Z",
     "iopub.execute_input": "2023-10-25T22:44:58.014023Z",
     "iopub.status.idle": "2023-10-25T22:44:58.077024Z",
     "shell.execute_reply.started": "2023-10-25T22:44:58.013990Z",
     "shell.execute_reply": "2023-10-25T22:44:58.075043Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:07.828649200Z",
     "start_time": "2023-12-03T13:49:07.745199400Z"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col id is integer. range: 0-9999. unique: 10000\n",
      "col name is string. range: 7-26. unique: 9382\n",
      "col email is string. range: 12-41. unique: 9946\n",
      "col phone is string. range: 10-13. unique: 10000\n",
      "col company is string. range: 6-33. unique: 8675\n",
      "col street is string. range: 7-22. unique: 9470\n",
      "col street_number is integer. range: 1-1000. unique: 1000\n",
      "col zipcode is integer. range: 519-99948. unique: 9508\n",
      "col country is string. range: 4-51. unique: 243\n",
      "col birthdate is string. range: 8-10. unique: 6787\n",
      "col deleted is integer. range: 0-0. unique: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maksim\\AppData\\Local\\Temp\\ipykernel_4976\\3904639341.py:3: FutureWarning: is_int64_dtype is deprecated and will be removed in a future version. Use dtype == np.int64 instead.\n",
      "  if pd.api.types.is_int64_dtype(df[col].iloc[0]):\n",
      "C:\\Users\\Maksim\\AppData\\Local\\Temp\\ipykernel_4976\\3904639341.py:3: FutureWarning: is_int64_dtype is deprecated and will be removed in a future version. Use dtype == np.int64 instead.\n",
      "  if pd.api.types.is_int64_dtype(df[col].iloc[0]):\n",
      "C:\\Users\\Maksim\\AppData\\Local\\Temp\\ipykernel_4976\\3904639341.py:3: FutureWarning: is_int64_dtype is deprecated and will be removed in a future version. Use dtype == np.int64 instead.\n",
      "  if pd.api.types.is_int64_dtype(df[col].iloc[0]):\n",
      "C:\\Users\\Maksim\\AppData\\Local\\Temp\\ipykernel_4976\\3904639341.py:3: FutureWarning: is_int64_dtype is deprecated and will be removed in a future version. Use dtype == np.int64 instead.\n",
      "  if pd.api.types.is_int64_dtype(df[col].iloc[0]):\n",
      "C:\\Users\\Maksim\\AppData\\Local\\Temp\\ipykernel_4976\\3904639341.py:3: FutureWarning: is_int64_dtype is deprecated and will be removed in a future version. Use dtype == np.int64 instead.\n",
      "  if pd.api.types.is_int64_dtype(df[col].iloc[0]):\n",
      "C:\\Users\\Maksim\\AppData\\Local\\Temp\\ipykernel_4976\\3904639341.py:3: FutureWarning: is_int64_dtype is deprecated and will be removed in a future version. Use dtype == np.int64 instead.\n",
      "  if pd.api.types.is_int64_dtype(df[col].iloc[0]):\n",
      "C:\\Users\\Maksim\\AppData\\Local\\Temp\\ipykernel_4976\\3904639341.py:3: FutureWarning: is_int64_dtype is deprecated and will be removed in a future version. Use dtype == np.int64 instead.\n",
      "  if pd.api.types.is_int64_dtype(df[col].iloc[0]):\n",
      "C:\\Users\\Maksim\\AppData\\Local\\Temp\\ipykernel_4976\\3904639341.py:3: FutureWarning: is_int64_dtype is deprecated and will be removed in a future version. Use dtype == np.int64 instead.\n",
      "  if pd.api.types.is_int64_dtype(df[col].iloc[0]):\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encode and decode tuple to fixed-lengh binary string"
   ],
   "metadata": {
    "id": "2qNCEmXgZOYo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#convert tuple to binary\n",
    "import struct #See https://docs.python.org/3/library/struct.html\n",
    "\n",
    "\"\"\"\n",
    "Using struct python package to convert to binary vector\n",
    "\">\" : litle endian (general format that defined order)\n",
    "\"H\" \" unsigned short integer (2 bytes )\n",
    "\"I\" :  unsigned integer (4 bytes)\n",
    "\"32s\" = string of max length 32 (32 bytes). If string is smaller, padding with 0 (less efficient)\n",
    "columns: ['id','name','email','phone','company','street','street_number', 'zipcode','country','birthdate']\n",
    "            I    32s    64s      16s     64s      32s          H             I          64s      16s\n",
    "\"\"\"\n",
    "format = '>I32s64s16s64s32sHI64s16sI'\n",
    "size_user = struct.calcsize(format)\n",
    "print(f'size of user: {size_user}B')\n",
    "\n",
    "def encode_user(user_row):\n",
    "  \"\"\"\n",
    "  Convert user tuple to fixed-length binary vector\n",
    "  :param user_row: user tuple/array where colums are ['id','name','email','phone',...]\n",
    "  :return: binary representation of user tuple\n",
    "  \"\"\"\n",
    "  values = [ value.encode('ascii') if isinstance(value,str) else value for value in user_row]\n",
    "  binary_string = struct.pack(format, *values)\n",
    "  return binary_string\n",
    "\n",
    "def decode_user(binary_string):\n",
    "  \"\"\"\n",
    "  Convert from  fixed-length binary vector to user_tuple\n",
    "  :param binary_string: user as binary string\n",
    "  :return: user tuple with ['id','name','email','phone',...]\n",
    "  \"\"\"\n",
    "  values = struct.unpack(format, binary_string)\n",
    "  values = [ value.decode('ascii').replace('\\x00','') if not isinstance(value,int) else value for value in values]\n",
    "  return values\n",
    "\n",
    "#test:\n",
    "first_row = df.iloc[0]\n",
    "binary_row = encode_user(first_row)\n",
    "print(f'first user: {first_row.values}')\n",
    "print(binary_row)\n",
    "print(f'encode: {len(binary_row)}')\n",
    "#Remark that binary size is very large, due to padding to fixed length\n",
    "#One solution (not implemented) is to work with varying length tuples,\n",
    "#i.e. storing the length first and the characterd \"3abc\" instead of fixed-length padding like \"00000000000abc\"\n",
    "first_row = decode_user(binary_row)\n",
    "print(f'decode_user: {first_row}')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vorXxo1b3TDv",
    "outputId": "82c22698-a18b-4ede-f459-ed6ed9894ab3",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:58.079516Z",
     "iopub.execute_input": "2023-10-25T22:44:58.080173Z",
     "iopub.status.idle": "2023-10-25T22:44:58.095197Z",
     "shell.execute_reply.started": "2023-10-25T22:44:58.080123Z",
     "shell.execute_reply": "2023-10-25T22:44:58.092954Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:07.869180600Z",
     "start_time": "2023-12-03T13:49:07.776237300Z"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of user: 302B\n",
      "first user: [0 'Patricia Smith' 'eriksmith@hotmail.com' '7326407883' 'Wells-Mendez'\n",
      " 'Julie Creek' 604 51907 'Falkland Islands (Malvinas)' '1982-1-12' 0]\n",
      "b'\\x00\\x00\\x00\\x00Patricia Smith\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00eriksmith@hotmail.com\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x007326407883\\x00\\x00\\x00\\x00\\x00\\x00Wells-Mendez\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00Julie Creek\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\\\\\x00\\x00\\xca\\xc3Falkland Islands (Malvinas)\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x001982-1-12\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
      "encode: 302\n",
      "decode_user: [0, 'Patricia Smith', 'eriksmith@hotmail.com', '7326407883', 'Wells-Mendez', 'Julie Creek', 604, 51907, 'Falkland Islands (Malvinas)', '1982-1-12', 0]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 1: Save and load to binary file\n",
    "\n",
    "**Exercise 1: Complete code to save and load from binary file**\n",
    "\n",
    "Use *file* from python, see https://docs.python.org/3/tutorial/inputoutput.html\n",
    "\n",
    "*file* API:\n",
    "\n",
    "- *fh = open(filename, mode)*, e.g. mode can be \"rb\" (read binary), \"rw\" (write new binary file) or \"r+b\" (read and write existing binary file)\n",
    "- *fh.read(N)* returns byte array with *N* bytes or False if nothing to read\n",
    "- *fh.write(bytearray)* write (or appends) bytearray at current position\n",
    "- *fh.seek(N)* go to file position starting at *N* bytes"
   ],
   "metadata": {
    "id": "PU7hOxLlaK1r"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def save_users_to_binary_file(filename, df):\n",
    "    \"\"\"\n",
    "    Saves users to sorted fixed-length binary file\n",
    "    :param filename: binary file to save\n",
    "    :param df: pandas dataframe contains all users\n",
    "    :return:\n",
    "    \"\"\"\n",
    "#     start = time.time()\n",
    "#     file = open(filename, \"wb\")\n",
    "#     nr_of_rows = df.shape[0]\n",
    "#     for i in range(0, nr_of_rows):\n",
    "#         file.write(encode_user(df.iloc[i])) # df.iloc[i] is the i-th user tuple\n",
    "#     file.close()\n",
    "#     print(f'saved {nr_of_rows} records to {filename}. Time: {time.time() -start}s')\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "#     # Open the binary file in binary write mode\n",
    "#     with open(filename, \"wb\") as file:\n",
    "#         # Encode all user rows and write them to the binary file\n",
    "#         for _, row in df.iterrows():\n",
    "#             binary_row = encode_user(row)\n",
    "#             file.write(binary_row)\n",
    "\n",
    "    with open(filename, \"wb\") as file: # 0.18\n",
    "        # Apply the encode_function to each row in the DataFrame and write to the file\n",
    "        df.apply(lambda row: file.write(encode_user(row)), axis=1)\n",
    "\n",
    "    print(f'saved {df.shape[0]} records to {filename}. Time: {time.time() - start}s')\n",
    "\n",
    "def load_user_from_binary_file(filename,user_columns=user_columns):\n",
    "    \"\"\"\n",
    "    Loads users from sorted fixed-length binary file\n",
    "    :param filename: binary file to load\n",
    "    :user_columns: name of columns\n",
    "    :return: pandas dataframe with all user tuples\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    users = []\n",
    "\n",
    "    file = open(filename, \"rb\")\n",
    "    file.seek(0, 2) # seeking to the very end of the file\n",
    "    file_size = file.tell() # current position = last byte of the file\n",
    "    nr_of_rows = int(file_size / size_user)\n",
    "    file.seek(0)\n",
    "\n",
    "    for i in range(0, nr_of_rows):\n",
    "        user_to_load = decode_user(file.read(size_user))\n",
    "        if user_to_load[10] == 0:  # user isn't deleted\n",
    "           users.append(user_to_load)\n",
    "    file.close()\n",
    "    print(f'loaded {nr_of_rows} records from {filename}. Time: {time.time() -start}s')\n",
    "    df = pd.DataFrame(users,columns=user_columns)\n",
    "    return df"
   ],
   "metadata": {
    "id": "z9Ag1ZX7aMu_",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:58.097668Z",
     "iopub.execute_input": "2023-10-25T22:44:58.098172Z",
     "iopub.status.idle": "2023-10-25T22:44:58.114562Z",
     "shell.execute_reply.started": "2023-10-25T22:44:58.098138Z",
     "shell.execute_reply": "2023-10-25T22:44:58.112848Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:07.887171700Z",
     "start_time": "2023-12-03T13:49:07.794771800Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#save\n",
    "fname_bin = 'fake_users.bin'\n",
    "save_users_to_binary_file(fname_bin, df)\n",
    "file_size = os.stat(fname_bin).st_size\n",
    "print(f\"File size is {file_size}B\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDVRFdUIYEg4",
    "outputId": "768985b8-18ab-4dd0-efce-cf8f55e28a42",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:58.116424Z",
     "iopub.execute_input": "2023-10-25T22:44:58.116840Z",
     "iopub.status.idle": "2023-10-25T22:44:58.254439Z",
     "shell.execute_reply.started": "2023-10-25T22:44:58.116806Z",
     "shell.execute_reply": "2023-10-25T22:44:58.253543Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:08.024607300Z",
     "start_time": "2023-12-03T13:49:07.808792100Z"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 10000 records to fake_users.bin. Time: 0.03988337516784668s\n",
      "File size is 3020000B\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#load\n",
    "df2 = load_user_from_binary_file(fname_bin)\n",
    "display(df2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "SKqJ7sGlejYP",
    "outputId": "4e35a50c-6df6-4b8d-e72a-2a5b5f80d10a",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:58.255607Z",
     "iopub.execute_input": "2023-10-25T22:44:58.255938Z",
     "iopub.status.idle": "2023-10-25T22:44:58.382197Z",
     "shell.execute_reply.started": "2023-10-25T22:44:58.255908Z",
     "shell.execute_reply": "2023-10-25T22:44:58.380973Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:08.055744200Z",
     "start_time": "2023-12-03T13:49:07.855671Z"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 10000 records from fake_users.bin. Time: 0.030501127243041992s\n"
     ]
    },
    {
     "data": {
      "text/plain": "        id               name                                 email  \\\n0        0     Patricia Smith                 eriksmith@hotmail.com   \n1        1     Kenneth George            walterswhitney@hotmail.com   \n2        2   Christine Harris                  yferguson@hudson.com   \n3        3      Alison Dennis                  jonathan83@gmail.com   \n4        4  Stephanie Wilkins              kevinchavez@williams.biz   \n...    ...                ...                                   ...   \n9995  9995     Heather Moreno  shannonsanchez@thompson-thompson.com   \n9996  9996     Jose Henderson                      kgreen@gmail.com   \n9997  9997         Kari Jones             donna83@adams-johnson.org   \n9998  9998        Denise Cook        lanesamantha@carney-doyle.info   \n9999  9999       Walter Smith                   fpotter@hotmail.com   \n\n              phone                    company           street  \\\n0        7326407883               Wells-Mendez      Julie Creek   \n1      362-637-0162             Jones and Sons     Denise Walks   \n2     (748)937-3676                  Adams PLC    Michael Ferry   \n3     (856)251-1000  Gomez, Holloway and Dixon     Wood Squares   \n4      563-847-5604    Atkinson, Lee and Singh   Friedman Lakes   \n...             ...                        ...              ...   \n9995  (902)326-9417             Jones and Sons    Heather Ville   \n9996   588-943-1228                Jones-Lewis  Daniel Crossing   \n9997     3098697653    Lamb, Cummings and Dunn     King Highway   \n9998  (636)382-0743                  Floyd Ltd       Watson Way   \n9999  (307)925-0245             Sampson-Torres     Jenna Stream   \n\n      street_number  zipcode  \\\n0               604    51907   \n1               141    10459   \n2                61    17092   \n3               994    75845   \n4               715    69102   \n...             ...      ...   \n9995            741    40316   \n9996             26    95087   \n9997            859    49790   \n9998            147    26443   \n9999            671    31158   \n\n                                                country  birthdate  deleted  \n0                           Falkland Islands (Malvinas)  1982-1-12        0  \n1                                                Bhutan   1976-6-1        0  \n2                                                 Italy  1973-7-16        0  \n3                                              Botswana  1979-8-25        0  \n4                                          South Africa  1984-12-8        0  \n...                                                 ...        ...      ...  \n9995                                              Ghana  1995-1-15        0  \n9996                                   Saint Barthelemy  1984-9-21        0  \n9997  British Indian Ocean Territory (Chagos Archipe...   1983-8-9        0  \n9998                                              China  1992-5-15        0  \n9999                                            Andorra   1981-1-2        0  \n\n[10000 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>email</th>\n      <th>phone</th>\n      <th>company</th>\n      <th>street</th>\n      <th>street_number</th>\n      <th>zipcode</th>\n      <th>country</th>\n      <th>birthdate</th>\n      <th>deleted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Patricia Smith</td>\n      <td>eriksmith@hotmail.com</td>\n      <td>7326407883</td>\n      <td>Wells-Mendez</td>\n      <td>Julie Creek</td>\n      <td>604</td>\n      <td>51907</td>\n      <td>Falkland Islands (Malvinas)</td>\n      <td>1982-1-12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Kenneth George</td>\n      <td>walterswhitney@hotmail.com</td>\n      <td>362-637-0162</td>\n      <td>Jones and Sons</td>\n      <td>Denise Walks</td>\n      <td>141</td>\n      <td>10459</td>\n      <td>Bhutan</td>\n      <td>1976-6-1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Christine Harris</td>\n      <td>yferguson@hudson.com</td>\n      <td>(748)937-3676</td>\n      <td>Adams PLC</td>\n      <td>Michael Ferry</td>\n      <td>61</td>\n      <td>17092</td>\n      <td>Italy</td>\n      <td>1973-7-16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Alison Dennis</td>\n      <td>jonathan83@gmail.com</td>\n      <td>(856)251-1000</td>\n      <td>Gomez, Holloway and Dixon</td>\n      <td>Wood Squares</td>\n      <td>994</td>\n      <td>75845</td>\n      <td>Botswana</td>\n      <td>1979-8-25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Stephanie Wilkins</td>\n      <td>kevinchavez@williams.biz</td>\n      <td>563-847-5604</td>\n      <td>Atkinson, Lee and Singh</td>\n      <td>Friedman Lakes</td>\n      <td>715</td>\n      <td>69102</td>\n      <td>South Africa</td>\n      <td>1984-12-8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>9995</td>\n      <td>Heather Moreno</td>\n      <td>shannonsanchez@thompson-thompson.com</td>\n      <td>(902)326-9417</td>\n      <td>Jones and Sons</td>\n      <td>Heather Ville</td>\n      <td>741</td>\n      <td>40316</td>\n      <td>Ghana</td>\n      <td>1995-1-15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>9996</td>\n      <td>Jose Henderson</td>\n      <td>kgreen@gmail.com</td>\n      <td>588-943-1228</td>\n      <td>Jones-Lewis</td>\n      <td>Daniel Crossing</td>\n      <td>26</td>\n      <td>95087</td>\n      <td>Saint Barthelemy</td>\n      <td>1984-9-21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>9997</td>\n      <td>Kari Jones</td>\n      <td>donna83@adams-johnson.org</td>\n      <td>3098697653</td>\n      <td>Lamb, Cummings and Dunn</td>\n      <td>King Highway</td>\n      <td>859</td>\n      <td>49790</td>\n      <td>British Indian Ocean Territory (Chagos Archipe...</td>\n      <td>1983-8-9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>9998</td>\n      <td>Denise Cook</td>\n      <td>lanesamantha@carney-doyle.info</td>\n      <td>(636)382-0743</td>\n      <td>Floyd Ltd</td>\n      <td>Watson Way</td>\n      <td>147</td>\n      <td>26443</td>\n      <td>China</td>\n      <td>1992-5-15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>9999</td>\n      <td>Walter Smith</td>\n      <td>fpotter@hotmail.com</td>\n      <td>(307)925-0245</td>\n      <td>Sampson-Torres</td>\n      <td>Jenna Stream</td>\n      <td>671</td>\n      <td>31158</td>\n      <td>Andorra</td>\n      <td>1981-1-2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Excercise 2: Random access\n",
    "\n",
    "**Exercise 2: Complete code to save and load single a record using random access (i.e. file.seek)**\n",
    "\n"
   ],
   "metadata": {
    "id": "OqTFE0UAecI4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from logging import FileHandler\n",
    "def read_user(user_id, fh):\n",
    "    \"\"\"\n",
    "    Random access to read fixed-length user tuple in sorted file\n",
    "    :param user_id: id of user data to read\n",
    "    :param fh: file handle\n",
    "    :return: decoded user tuple\n",
    "    \"\"\"\n",
    "    offset = user_id * size_user\n",
    "    fh.seek(offset)\n",
    "    binary_row = fh.read(size_user)\n",
    "    user_tuple = decode_user(binary_row)\n",
    "\n",
    "    # user is deleted\n",
    "    if user_tuple[10] == 1:\n",
    "      return None\n",
    "\n",
    "    return user_tuple\n",
    "\n",
    "def write_user(user, fh):\n",
    "    \"\"\"\n",
    "    Random acces to write/update fixed-length user tuple in sorted file\n",
    "    :param user: user tuple/array where colums are ['id','name','email','phone',...]\n",
    "    :param fh: file handle\n",
    "    :return: -updated-user-tuple-in-file/ => void\n",
    "    \"\"\"\n",
    "    offset = user[0] * size_user\n",
    "    fh.seek(offset)\n",
    "    binary_row = encode_user(user)\n",
    "    fh.write(binary_row)\n",
    "\n",
    "def delete_user(user_id, fh):\n",
    "    \"\"\"\n",
    "    Delete user from database\n",
    "    :param user_id: id of user data to delete\n",
    "    :param fh: file handle\n",
    "    :return: bool success\n",
    "    \"\"\"\n",
    "    user_to_delete = read_user(user_id, fh)\n",
    "\n",
    "    # already deleted\n",
    "    if user_to_delete is None:\n",
    "      return False\n",
    "\n",
    "    else:\n",
    "      user_to_delete[10] = 1\n",
    "      write_user(user_to_delete, fh)\n",
    "      return True\n",
    "\n",
    "def insert_user(user, fh):\n",
    "    \"\"\"\n",
    "    Insert user in database\n",
    "    :param user: user to insert\n",
    "    :param fh: file handle\n",
    "    :return: bool success\n",
    "    \"\"\"\n",
    "    fh.seek(0, 2) # seeking to the very end of the file\n",
    "    file_size = fh.tell() # current position = last byte of the file\n",
    "    new_id = int(file_size / size_user)\n",
    "    user = [new_id] + user\n",
    "\n",
    "    offset = file_size\n",
    "    fh.seek(offset)\n",
    "    binary_row = encode_user(user)\n",
    "    fh.write(binary_row)\n",
    "\n",
    "    return True\n"
   ],
   "metadata": {
    "id": "Kev7m_QqebpT",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:58.386290Z",
     "iopub.execute_input": "2023-10-25T22:44:58.386597Z",
     "iopub.status.idle": "2023-10-25T22:44:58.397487Z",
     "shell.execute_reply.started": "2023-10-25T22:44:58.386572Z",
     "shell.execute_reply": "2023-10-25T22:44:58.396071Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:08.057744800Z",
     "start_time": "2023-12-03T13:49:07.903766600Z"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Read 4 random users\n",
    "fh = open(fname_bin,\"rb\")\n",
    "start = time.time()\n",
    "random_ids = [0, 100, 200, 9999]\n",
    "random_users = []\n",
    "for id in random_ids:\n",
    "  user_i = read_user(id, fh)\n",
    "  random_users.append(user_i)\n",
    "print(f'Loading {len(random_ids)} random users. Elapsed: {time.time() -start}s')\n",
    "fh.close()\n",
    "df_sample = pd.DataFrame(random_users,columns=user_columns)\n",
    "display(df_sample)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "OeLJyhKKa76f",
    "outputId": "387f15c4-30bb-43bc-fefb-6aef8d9be580",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:58.399278Z",
     "iopub.execute_input": "2023-10-25T22:44:58.399693Z",
     "iopub.status.idle": "2023-10-25T22:44:58.425199Z",
     "shell.execute_reply.started": "2023-10-25T22:44:58.399658Z",
     "shell.execute_reply": "2023-10-25T22:44:58.423288Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:08.063954700Z",
     "start_time": "2023-12-03T13:49:07.919214400Z"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 4 random users. Elapsed: 0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": "     id            name                            email          phone  \\\n0     0  Patricia Smith            eriksmith@hotmail.com     7326407883   \n1   100   Daniel Hansen           hicksmichael@yahoo.com     8508054624   \n2   200     Kelsey Cole  campbellveronica@yates-long.org   589-395-1226   \n3  9999    Walter Smith              fpotter@hotmail.com  (307)925-0245   \n\n          company         street  street_number  zipcode  \\\n0    Wells-Mendez    Julie Creek            604    51907   \n1   Moran-Morales  Zachary Plain            551    98871   \n2   Deleon-Conley     Lisa Route            701    91592   \n3  Sampson-Torres   Jenna Stream            671    31158   \n\n                       country  birthdate  deleted  \n0  Falkland Islands (Malvinas)  1982-1-12        0  \n1  French Southern Territories  1971-6-21        0  \n2            Equatorial Guinea  1970-9-13        0  \n3                      Andorra   1981-1-2        0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>email</th>\n      <th>phone</th>\n      <th>company</th>\n      <th>street</th>\n      <th>street_number</th>\n      <th>zipcode</th>\n      <th>country</th>\n      <th>birthdate</th>\n      <th>deleted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Patricia Smith</td>\n      <td>eriksmith@hotmail.com</td>\n      <td>7326407883</td>\n      <td>Wells-Mendez</td>\n      <td>Julie Creek</td>\n      <td>604</td>\n      <td>51907</td>\n      <td>Falkland Islands (Malvinas)</td>\n      <td>1982-1-12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>Daniel Hansen</td>\n      <td>hicksmichael@yahoo.com</td>\n      <td>8508054624</td>\n      <td>Moran-Morales</td>\n      <td>Zachary Plain</td>\n      <td>551</td>\n      <td>98871</td>\n      <td>French Southern Territories</td>\n      <td>1971-6-21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>200</td>\n      <td>Kelsey Cole</td>\n      <td>campbellveronica@yates-long.org</td>\n      <td>589-395-1226</td>\n      <td>Deleon-Conley</td>\n      <td>Lisa Route</td>\n      <td>701</td>\n      <td>91592</td>\n      <td>Equatorial Guinea</td>\n      <td>1970-9-13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9999</td>\n      <td>Walter Smith</td>\n      <td>fpotter@hotmail.com</td>\n      <td>(307)925-0245</td>\n      <td>Sampson-Torres</td>\n      <td>Jenna Stream</td>\n      <td>671</td>\n      <td>31158</td>\n      <td>Andorra</td>\n      <td>1981-1-2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#Update 4 random users\n",
    "fh = open(fname_bin,\"r+b\") #open file for updating with \"r+b\", do not use \"wb\" since otherwise file will be blank!\n",
    "start = time.time()\n",
    "random_ids = [0, 100, 200, 9999]\n",
    "for user in random_users:\n",
    "  user[1] = 'X ' + user[1]\n",
    "  write_user(user,fh)\n",
    "print(f'Writing {len(random_ids)} random users. Elapsed: {time.time() -start}s')\n",
    "fh.close()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gGT2KmkcdrtN",
    "outputId": "5231a3de-e64f-43e6-b798-d95d4e7e2dbd",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:58.427330Z",
     "iopub.execute_input": "2023-10-25T22:44:58.427714Z",
     "iopub.status.idle": "2023-10-25T22:44:58.447861Z",
     "shell.execute_reply.started": "2023-10-25T22:44:58.427682Z",
     "shell.execute_reply": "2023-10-25T22:44:58.446161Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:08.063954700Z",
     "start_time": "2023-12-03T13:49:07.934728Z"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 4 random users. Elapsed: 0.0s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Check to see if users have been updated (X in front of name)\n",
    "fh = open(fname_bin,\"rb\")\n",
    "start = time.time()\n",
    "random_ids = [0, 100, 200, 9999]\n",
    "random_users = []\n",
    "for id in random_ids:\n",
    "  user_i = read_user(id, fh)\n",
    "  random_users.append(user_i)\n",
    "print(f'Loading {len(random_ids)} random users. Elapsed: {time.time() -start}s')\n",
    "fh.close()\n",
    "df_sample = pd.DataFrame(random_users,columns=user_columns)\n",
    "display(df_sample)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "EuArPkFpNelP",
    "outputId": "186f4729-6782-465e-dbc6-13e7d7f6f4ee",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:58.449341Z",
     "iopub.execute_input": "2023-10-25T22:44:58.449766Z",
     "iopub.status.idle": "2023-10-25T22:44:58.475259Z",
     "shell.execute_reply.started": "2023-10-25T22:44:58.449725Z",
     "shell.execute_reply": "2023-10-25T22:44:58.474357Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:08.063954700Z",
     "start_time": "2023-12-03T13:49:07.950262700Z"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 4 random users. Elapsed: 0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": "     id              name                            email          phone  \\\n0     0  X Patricia Smith            eriksmith@hotmail.com     7326407883   \n1   100   X Daniel Hansen           hicksmichael@yahoo.com     8508054624   \n2   200     X Kelsey Cole  campbellveronica@yates-long.org   589-395-1226   \n3  9999    X Walter Smith              fpotter@hotmail.com  (307)925-0245   \n\n          company         street  street_number  zipcode  \\\n0    Wells-Mendez    Julie Creek            604    51907   \n1   Moran-Morales  Zachary Plain            551    98871   \n2   Deleon-Conley     Lisa Route            701    91592   \n3  Sampson-Torres   Jenna Stream            671    31158   \n\n                       country  birthdate  deleted  \n0  Falkland Islands (Malvinas)  1982-1-12        0  \n1  French Southern Territories  1971-6-21        0  \n2            Equatorial Guinea  1970-9-13        0  \n3                      Andorra   1981-1-2        0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>email</th>\n      <th>phone</th>\n      <th>company</th>\n      <th>street</th>\n      <th>street_number</th>\n      <th>zipcode</th>\n      <th>country</th>\n      <th>birthdate</th>\n      <th>deleted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>X Patricia Smith</td>\n      <td>eriksmith@hotmail.com</td>\n      <td>7326407883</td>\n      <td>Wells-Mendez</td>\n      <td>Julie Creek</td>\n      <td>604</td>\n      <td>51907</td>\n      <td>Falkland Islands (Malvinas)</td>\n      <td>1982-1-12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>X Daniel Hansen</td>\n      <td>hicksmichael@yahoo.com</td>\n      <td>8508054624</td>\n      <td>Moran-Morales</td>\n      <td>Zachary Plain</td>\n      <td>551</td>\n      <td>98871</td>\n      <td>French Southern Territories</td>\n      <td>1971-6-21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>200</td>\n      <td>X Kelsey Cole</td>\n      <td>campbellveronica@yates-long.org</td>\n      <td>589-395-1226</td>\n      <td>Deleon-Conley</td>\n      <td>Lisa Route</td>\n      <td>701</td>\n      <td>91592</td>\n      <td>Equatorial Guinea</td>\n      <td>1970-9-13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9999</td>\n      <td>X Walter Smith</td>\n      <td>fpotter@hotmail.com</td>\n      <td>(307)925-0245</td>\n      <td>Sampson-Torres</td>\n      <td>Jenna Stream</td>\n      <td>671</td>\n      <td>31158</td>\n      <td>Andorra</td>\n      <td>1981-1-2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Delete user by id\n",
    "fh = open(fname_bin,\"r+b\")\n",
    "start = time.time()\n",
    "ids_to_delete = [2] # use any\n",
    "for _id in ids_to_delete:\n",
    "  success = delete_user(_id, fh)\n",
    "  if not success:\n",
    "    print(\"User with id=\"+str(_id)+\" is already deleted!\")\n",
    "print(f'deleting {len(ids_to_delete)} random users. Elapsed: {time.time() -start}s')\n",
    "fh.close()\n",
    "df_after_delete = load_user_from_binary_file(fname_bin)\n",
    "display(df_after_delete)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "K6AfKKkUN3SR",
    "outputId": "203ab218-3033-4e5f-e427-8c37e66f8662",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:58.476369Z",
     "iopub.execute_input": "2023-10-25T22:44:58.476685Z",
     "iopub.status.idle": "2023-10-25T22:44:58.602423Z",
     "shell.execute_reply.started": "2023-10-25T22:44:58.476662Z",
     "shell.execute_reply": "2023-10-25T22:44:58.600343Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:08.084823100Z",
     "start_time": "2023-12-03T13:49:07.966384700Z"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting 1 random users. Elapsed: 0.0010042190551757812s\n",
      "loaded 10000 records from fake_users.bin. Time: 0.031154394149780273s\n"
     ]
    },
    {
     "data": {
      "text/plain": "        id               name                                 email  \\\n0        0   X Patricia Smith                 eriksmith@hotmail.com   \n1        1     Kenneth George            walterswhitney@hotmail.com   \n2        3      Alison Dennis                  jonathan83@gmail.com   \n3        4  Stephanie Wilkins              kevinchavez@williams.biz   \n4        5     Kathryn Davila             beth69@hines-campbell.com   \n...    ...                ...                                   ...   \n9994  9995     Heather Moreno  shannonsanchez@thompson-thompson.com   \n9995  9996     Jose Henderson                      kgreen@gmail.com   \n9996  9997         Kari Jones             donna83@adams-johnson.org   \n9997  9998        Denise Cook        lanesamantha@carney-doyle.info   \n9998  9999     X Walter Smith                   fpotter@hotmail.com   \n\n              phone                    company           street  \\\n0        7326407883               Wells-Mendez      Julie Creek   \n1      362-637-0162             Jones and Sons     Denise Walks   \n2     (856)251-1000  Gomez, Holloway and Dixon     Wood Squares   \n3      563-847-5604    Atkinson, Lee and Singh   Friedman Lakes   \n4      344-739-1382              Rogers-Barton       Tony Drive   \n...             ...                        ...              ...   \n9994  (902)326-9417             Jones and Sons    Heather Ville   \n9995   588-943-1228                Jones-Lewis  Daniel Crossing   \n9996     3098697653    Lamb, Cummings and Dunn     King Highway   \n9997  (636)382-0743                  Floyd Ltd       Watson Way   \n9998  (307)925-0245             Sampson-Torres     Jenna Stream   \n\n      street_number  zipcode  \\\n0               604    51907   \n1               141    10459   \n2               994    75845   \n3               715    69102   \n4               922    95201   \n...             ...      ...   \n9994            741    40316   \n9995             26    95087   \n9996            859    49790   \n9997            147    26443   \n9998            671    31158   \n\n                                                country  birthdate  deleted  \n0                           Falkland Islands (Malvinas)  1982-1-12        0  \n1                                                Bhutan   1976-6-1        0  \n2                                              Botswana  1979-8-25        0  \n3                                          South Africa  1984-12-8        0  \n4                                            Seychelles   1980-1-8        0  \n...                                                 ...        ...      ...  \n9994                                              Ghana  1995-1-15        0  \n9995                                   Saint Barthelemy  1984-9-21        0  \n9996  British Indian Ocean Territory (Chagos Archipe...   1983-8-9        0  \n9997                                              China  1992-5-15        0  \n9998                                            Andorra   1981-1-2        0  \n\n[9999 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>email</th>\n      <th>phone</th>\n      <th>company</th>\n      <th>street</th>\n      <th>street_number</th>\n      <th>zipcode</th>\n      <th>country</th>\n      <th>birthdate</th>\n      <th>deleted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>X Patricia Smith</td>\n      <td>eriksmith@hotmail.com</td>\n      <td>7326407883</td>\n      <td>Wells-Mendez</td>\n      <td>Julie Creek</td>\n      <td>604</td>\n      <td>51907</td>\n      <td>Falkland Islands (Malvinas)</td>\n      <td>1982-1-12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Kenneth George</td>\n      <td>walterswhitney@hotmail.com</td>\n      <td>362-637-0162</td>\n      <td>Jones and Sons</td>\n      <td>Denise Walks</td>\n      <td>141</td>\n      <td>10459</td>\n      <td>Bhutan</td>\n      <td>1976-6-1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Alison Dennis</td>\n      <td>jonathan83@gmail.com</td>\n      <td>(856)251-1000</td>\n      <td>Gomez, Holloway and Dixon</td>\n      <td>Wood Squares</td>\n      <td>994</td>\n      <td>75845</td>\n      <td>Botswana</td>\n      <td>1979-8-25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Stephanie Wilkins</td>\n      <td>kevinchavez@williams.biz</td>\n      <td>563-847-5604</td>\n      <td>Atkinson, Lee and Singh</td>\n      <td>Friedman Lakes</td>\n      <td>715</td>\n      <td>69102</td>\n      <td>South Africa</td>\n      <td>1984-12-8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Kathryn Davila</td>\n      <td>beth69@hines-campbell.com</td>\n      <td>344-739-1382</td>\n      <td>Rogers-Barton</td>\n      <td>Tony Drive</td>\n      <td>922</td>\n      <td>95201</td>\n      <td>Seychelles</td>\n      <td>1980-1-8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9994</th>\n      <td>9995</td>\n      <td>Heather Moreno</td>\n      <td>shannonsanchez@thompson-thompson.com</td>\n      <td>(902)326-9417</td>\n      <td>Jones and Sons</td>\n      <td>Heather Ville</td>\n      <td>741</td>\n      <td>40316</td>\n      <td>Ghana</td>\n      <td>1995-1-15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>9996</td>\n      <td>Jose Henderson</td>\n      <td>kgreen@gmail.com</td>\n      <td>588-943-1228</td>\n      <td>Jones-Lewis</td>\n      <td>Daniel Crossing</td>\n      <td>26</td>\n      <td>95087</td>\n      <td>Saint Barthelemy</td>\n      <td>1984-9-21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>9997</td>\n      <td>Kari Jones</td>\n      <td>donna83@adams-johnson.org</td>\n      <td>3098697653</td>\n      <td>Lamb, Cummings and Dunn</td>\n      <td>King Highway</td>\n      <td>859</td>\n      <td>49790</td>\n      <td>British Indian Ocean Territory (Chagos Archipe...</td>\n      <td>1983-8-9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>9998</td>\n      <td>Denise Cook</td>\n      <td>lanesamantha@carney-doyle.info</td>\n      <td>(636)382-0743</td>\n      <td>Floyd Ltd</td>\n      <td>Watson Way</td>\n      <td>147</td>\n      <td>26443</td>\n      <td>China</td>\n      <td>1992-5-15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>9999</td>\n      <td>X Walter Smith</td>\n      <td>fpotter@hotmail.com</td>\n      <td>(307)925-0245</td>\n      <td>Sampson-Torres</td>\n      <td>Jenna Stream</td>\n      <td>671</td>\n      <td>31158</td>\n      <td>Andorra</td>\n      <td>1981-1-2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>9999 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Insert user without id\n",
    "fh = open(fname_bin,\"r+b\")\n",
    "start = time.time()\n",
    "fake = Faker()\n",
    "new_user = [fake.name(), fake.ascii_email(), fake.basic_phone_number(), fake.company(), fake.street_name(), random.randint(1,1000), int(fake.zipcode()), fake.country(), f'{random.randint(1970,2005)}-{random.randint(1,12)}-{random.randint(1,28)}', 0]\n",
    "insert_success = insert_user(new_user, fh)\n",
    "fh.close()\n",
    "print(f'inserting random user. Elapsed: {time.time() -start}s')\n",
    "\n",
    "df_after_delete = load_user_from_binary_file(fname_bin)\n",
    "display(df_after_delete)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "kIdVsz9qfRzk",
    "outputId": "362a10b8-bac8-4609-c5e7-c4c28644bd40",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:58.604180Z",
     "iopub.execute_input": "2023-10-25T22:44:58.604539Z",
     "iopub.status.idle": "2023-10-25T22:44:58.751556Z",
     "shell.execute_reply.started": "2023-10-25T22:44:58.604513Z",
     "shell.execute_reply": "2023-10-25T22:44:58.750057Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:08.274115100Z",
     "start_time": "2023-12-03T13:49:08.028113700Z"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserting random user. Elapsed: 0.030134916305541992s\n",
      "loaded 10001 records from fake_users.bin. Time: 0.03559684753417969s\n"
     ]
    },
    {
     "data": {
      "text/plain": "         id               name                           email          phone  \\\n0         0   X Patricia Smith           eriksmith@hotmail.com     7326407883   \n1         1     Kenneth George      walterswhitney@hotmail.com   362-637-0162   \n2         3      Alison Dennis            jonathan83@gmail.com  (856)251-1000   \n3         4  Stephanie Wilkins        kevinchavez@williams.biz   563-847-5604   \n4         5     Kathryn Davila       beth69@hines-campbell.com   344-739-1382   \n...     ...                ...                             ...            ...   \n9995   9996     Jose Henderson                kgreen@gmail.com   588-943-1228   \n9996   9997         Kari Jones       donna83@adams-johnson.org     3098697653   \n9997   9998        Denise Cook  lanesamantha@carney-doyle.info  (636)382-0743   \n9998   9999     X Walter Smith             fpotter@hotmail.com  (307)925-0245   \n9999  10000     Kayla Carrillo          mcbridesusan@gmail.com     7603626453   \n\n                        company           street  street_number  zipcode  \\\n0                  Wells-Mendez      Julie Creek            604    51907   \n1                Jones and Sons     Denise Walks            141    10459   \n2     Gomez, Holloway and Dixon     Wood Squares            994    75845   \n3       Atkinson, Lee and Singh   Friedman Lakes            715    69102   \n4                 Rogers-Barton       Tony Drive            922    95201   \n...                         ...              ...            ...      ...   \n9995                Jones-Lewis  Daniel Crossing             26    95087   \n9996    Lamb, Cummings and Dunn     King Highway            859    49790   \n9997                  Floyd Ltd       Watson Way            147    26443   \n9998             Sampson-Torres     Jenna Stream            671    31158   \n9999                  Rush-Hall   Joanna Highway            179    18894   \n\n                                                country   birthdate  deleted  \n0                           Falkland Islands (Malvinas)   1982-1-12        0  \n1                                                Bhutan    1976-6-1        0  \n2                                              Botswana   1979-8-25        0  \n3                                          South Africa   1984-12-8        0  \n4                                            Seychelles    1980-1-8        0  \n...                                                 ...         ...      ...  \n9995                                   Saint Barthelemy   1984-9-21        0  \n9996  British Indian Ocean Territory (Chagos Archipe...    1983-8-9        0  \n9997                                              China   1992-5-15        0  \n9998                                            Andorra    1981-1-2        0  \n9999                                      Faroe Islands  1988-12-25        0  \n\n[10000 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>email</th>\n      <th>phone</th>\n      <th>company</th>\n      <th>street</th>\n      <th>street_number</th>\n      <th>zipcode</th>\n      <th>country</th>\n      <th>birthdate</th>\n      <th>deleted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>X Patricia Smith</td>\n      <td>eriksmith@hotmail.com</td>\n      <td>7326407883</td>\n      <td>Wells-Mendez</td>\n      <td>Julie Creek</td>\n      <td>604</td>\n      <td>51907</td>\n      <td>Falkland Islands (Malvinas)</td>\n      <td>1982-1-12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Kenneth George</td>\n      <td>walterswhitney@hotmail.com</td>\n      <td>362-637-0162</td>\n      <td>Jones and Sons</td>\n      <td>Denise Walks</td>\n      <td>141</td>\n      <td>10459</td>\n      <td>Bhutan</td>\n      <td>1976-6-1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Alison Dennis</td>\n      <td>jonathan83@gmail.com</td>\n      <td>(856)251-1000</td>\n      <td>Gomez, Holloway and Dixon</td>\n      <td>Wood Squares</td>\n      <td>994</td>\n      <td>75845</td>\n      <td>Botswana</td>\n      <td>1979-8-25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Stephanie Wilkins</td>\n      <td>kevinchavez@williams.biz</td>\n      <td>563-847-5604</td>\n      <td>Atkinson, Lee and Singh</td>\n      <td>Friedman Lakes</td>\n      <td>715</td>\n      <td>69102</td>\n      <td>South Africa</td>\n      <td>1984-12-8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Kathryn Davila</td>\n      <td>beth69@hines-campbell.com</td>\n      <td>344-739-1382</td>\n      <td>Rogers-Barton</td>\n      <td>Tony Drive</td>\n      <td>922</td>\n      <td>95201</td>\n      <td>Seychelles</td>\n      <td>1980-1-8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>9996</td>\n      <td>Jose Henderson</td>\n      <td>kgreen@gmail.com</td>\n      <td>588-943-1228</td>\n      <td>Jones-Lewis</td>\n      <td>Daniel Crossing</td>\n      <td>26</td>\n      <td>95087</td>\n      <td>Saint Barthelemy</td>\n      <td>1984-9-21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>9997</td>\n      <td>Kari Jones</td>\n      <td>donna83@adams-johnson.org</td>\n      <td>3098697653</td>\n      <td>Lamb, Cummings and Dunn</td>\n      <td>King Highway</td>\n      <td>859</td>\n      <td>49790</td>\n      <td>British Indian Ocean Territory (Chagos Archipe...</td>\n      <td>1983-8-9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>9998</td>\n      <td>Denise Cook</td>\n      <td>lanesamantha@carney-doyle.info</td>\n      <td>(636)382-0743</td>\n      <td>Floyd Ltd</td>\n      <td>Watson Way</td>\n      <td>147</td>\n      <td>26443</td>\n      <td>China</td>\n      <td>1992-5-15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>9999</td>\n      <td>X Walter Smith</td>\n      <td>fpotter@hotmail.com</td>\n      <td>(307)925-0245</td>\n      <td>Sampson-Torres</td>\n      <td>Jenna Stream</td>\n      <td>671</td>\n      <td>31158</td>\n      <td>Andorra</td>\n      <td>1981-1-2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>10000</td>\n      <td>Kayla Carrillo</td>\n      <td>mcbridesusan@gmail.com</td>\n      <td>7603626453</td>\n      <td>Rush-Hall</td>\n      <td>Joanna Highway</td>\n      <td>179</td>\n      <td>18894</td>\n      <td>Faroe Islands</td>\n      <td>1988-12-25</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compressed varying-length binary file\n"
   ],
   "metadata": {
    "id": "SaIuQu0UmGYW"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Excercise 3: Modify dataframe and encode country using bitmap encoding\n",
    "**Exercise 3: Encode country using bitmap encoding. You can assume the dictionary itself does not need to be stored**\n",
    "\n",
    "*Pandas* API:\n",
    "- *df[col]*: returns a single column with name *col* as series\n",
    "- *df[col].values*: returns a single column as *numpy* array\n",
    "- *list(df[col].values)*: returns a single column as *python* list\n",
    "- *df[col].unique()*: returns all unique (or distinct) values\n",
    "- *df[col].apply(f)*: applies (or runs) the function f to all column values\n",
    "- *df[col2] = df[col].apply(f)*: applies (or runs) the function f to all column values and store the result in a new column\n"
   ],
   "metadata": {
    "id": "g5KH0PMM2g8H"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def encode_dictionary(df, col):\n",
    "    \"\"\"\n",
    "    Creates column df[col + '_dct'] containing dictionary value\n",
    "    :param df: pandas dataframe\n",
    "    :param col: column to apply dictionary encoding\n",
    "    :return mapping between value and code\n",
    "    \"\"\"\n",
    "    unique_values = sorted(df[col].unique())\n",
    "    value_to_code = {}\n",
    "    for i in range(len(unique_values)):\n",
    "        value_to_code[unique_values[i]] = i\n",
    "    mapping = [(key,value) for key, value in value_to_code.items()]\n",
    "    df[\"country_dct\"] = df[\"country\"].map(value_to_code)\n",
    "    return mapping"
   ],
   "metadata": {
    "id": "uofrgerdmfTp",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:58.753588Z",
     "iopub.execute_input": "2023-10-25T22:44:58.755417Z",
     "iopub.status.idle": "2023-10-25T22:44:58.761852Z",
     "shell.execute_reply.started": "2023-10-25T22:44:58.755374Z",
     "shell.execute_reply": "2023-10-25T22:44:58.760688Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:08.289559900Z",
     "start_time": "2023-12-03T13:49:08.121734700Z"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Before: col country is string. range: 4-51. unique: 243\n",
    "After: country \"id\" encoded using dictionary and store as 16 bit integer\n",
    "\"\"\"\n",
    "value_to_code_countries = encode_dictionary(df,'country')\n",
    "print(value_to_code_countries)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yp7SvxsczR0V",
    "outputId": "23835c41-20fd-4f85-d4de-afe49270baad",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:58.763408Z",
     "iopub.execute_input": "2023-10-25T22:44:58.763762Z",
     "iopub.status.idle": "2023-10-25T22:44:58.782599Z",
     "shell.execute_reply.started": "2023-10-25T22:44:58.763730Z",
     "shell.execute_reply": "2023-10-25T22:44:58.780234Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:08.305081600Z",
     "start_time": "2023-12-03T13:49:08.135751Z"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Afghanistan', 0), ('Albania', 1), ('Algeria', 2), ('American Samoa', 3), ('Andorra', 4), ('Angola', 5), ('Anguilla', 6), ('Antarctica (the territory South of 60 deg S)', 7), ('Antigua and Barbuda', 8), ('Argentina', 9), ('Armenia', 10), ('Aruba', 11), ('Australia', 12), ('Austria', 13), ('Azerbaijan', 14), ('Bahamas', 15), ('Bahrain', 16), ('Bangladesh', 17), ('Barbados', 18), ('Belarus', 19), ('Belgium', 20), ('Belize', 21), ('Benin', 22), ('Bermuda', 23), ('Bhutan', 24), ('Bolivia', 25), ('Bosnia and Herzegovina', 26), ('Botswana', 27), ('Bouvet Island (Bouvetoya)', 28), ('Brazil', 29), ('British Indian Ocean Territory (Chagos Archipelago)', 30), ('British Virgin Islands', 31), ('Brunei Darussalam', 32), ('Bulgaria', 33), ('Burkina Faso', 34), ('Burundi', 35), ('Cambodia', 36), ('Cameroon', 37), ('Canada', 38), ('Cape Verde', 39), ('Cayman Islands', 40), ('Central African Republic', 41), ('Chad', 42), ('Chile', 43), ('China', 44), ('Christmas Island', 45), ('Cocos (Keeling) Islands', 46), ('Colombia', 47), ('Comoros', 48), ('Congo', 49), ('Cook Islands', 50), ('Costa Rica', 51), (\"Cote d'Ivoire\", 52), ('Croatia', 53), ('Cuba', 54), ('Cyprus', 55), ('Czech Republic', 56), ('Denmark', 57), ('Djibouti', 58), ('Dominica', 59), ('Dominican Republic', 60), ('Ecuador', 61), ('Egypt', 62), ('El Salvador', 63), ('Equatorial Guinea', 64), ('Eritrea', 65), ('Estonia', 66), ('Ethiopia', 67), ('Falkland Islands (Malvinas)', 68), ('Faroe Islands', 69), ('Fiji', 70), ('Finland', 71), ('France', 72), ('French Guiana', 73), ('French Polynesia', 74), ('French Southern Territories', 75), ('Gabon', 76), ('Gambia', 77), ('Georgia', 78), ('Germany', 79), ('Ghana', 80), ('Gibraltar', 81), ('Greece', 82), ('Greenland', 83), ('Grenada', 84), ('Guadeloupe', 85), ('Guam', 86), ('Guatemala', 87), ('Guernsey', 88), ('Guinea', 89), ('Guinea-Bissau', 90), ('Guyana', 91), ('Haiti', 92), ('Heard Island and McDonald Islands', 93), ('Holy See (Vatican City State)', 94), ('Honduras', 95), ('Hong Kong', 96), ('Hungary', 97), ('Iceland', 98), ('India', 99), ('Indonesia', 100), ('Iran', 101), ('Iraq', 102), ('Ireland', 103), ('Isle of Man', 104), ('Israel', 105), ('Italy', 106), ('Jamaica', 107), ('Japan', 108), ('Jersey', 109), ('Jordan', 110), ('Kazakhstan', 111), ('Kenya', 112), ('Kiribati', 113), ('Korea', 114), ('Kuwait', 115), ('Kyrgyz Republic', 116), (\"Lao People's Democratic Republic\", 117), ('Latvia', 118), ('Lebanon', 119), ('Lesotho', 120), ('Liberia', 121), ('Libyan Arab Jamahiriya', 122), ('Liechtenstein', 123), ('Lithuania', 124), ('Luxembourg', 125), ('Macao', 126), ('Madagascar', 127), ('Malawi', 128), ('Malaysia', 129), ('Maldives', 130), ('Mali', 131), ('Malta', 132), ('Marshall Islands', 133), ('Martinique', 134), ('Mauritania', 135), ('Mauritius', 136), ('Mayotte', 137), ('Mexico', 138), ('Micronesia', 139), ('Moldova', 140), ('Monaco', 141), ('Mongolia', 142), ('Montenegro', 143), ('Montserrat', 144), ('Morocco', 145), ('Mozambique', 146), ('Myanmar', 147), ('Namibia', 148), ('Nauru', 149), ('Nepal', 150), ('Netherlands', 151), ('Netherlands Antilles', 152), ('New Caledonia', 153), ('New Zealand', 154), ('Nicaragua', 155), ('Niger', 156), ('Nigeria', 157), ('Niue', 158), ('Norfolk Island', 159), ('North Macedonia', 160), ('Northern Mariana Islands', 161), ('Norway', 162), ('Oman', 163), ('Pakistan', 164), ('Palau', 165), ('Palestinian Territory', 166), ('Panama', 167), ('Papua New Guinea', 168), ('Paraguay', 169), ('Peru', 170), ('Philippines', 171), ('Pitcairn Islands', 172), ('Poland', 173), ('Portugal', 174), ('Puerto Rico', 175), ('Qatar', 176), ('Reunion', 177), ('Romania', 178), ('Russian Federation', 179), ('Rwanda', 180), ('Saint Barthelemy', 181), ('Saint Helena', 182), ('Saint Kitts and Nevis', 183), ('Saint Lucia', 184), ('Saint Martin', 185), ('Saint Pierre and Miquelon', 186), ('Saint Vincent and the Grenadines', 187), ('Samoa', 188), ('San Marino', 189), ('Sao Tome and Principe', 190), ('Saudi Arabia', 191), ('Senegal', 192), ('Serbia', 193), ('Seychelles', 194), ('Sierra Leone', 195), ('Singapore', 196), ('Slovakia (Slovak Republic)', 197), ('Slovenia', 198), ('Solomon Islands', 199), ('Somalia', 200), ('South Africa', 201), ('South Georgia and the South Sandwich Islands', 202), ('Spain', 203), ('Sri Lanka', 204), ('Sudan', 205), ('Suriname', 206), ('Svalbard & Jan Mayen Islands', 207), ('Swaziland', 208), ('Sweden', 209), ('Switzerland', 210), ('Syrian Arab Republic', 211), ('Taiwan', 212), ('Tajikistan', 213), ('Tanzania', 214), ('Thailand', 215), ('Timor-Leste', 216), ('Togo', 217), ('Tokelau', 218), ('Tonga', 219), ('Trinidad and Tobago', 220), ('Tunisia', 221), ('Turkey', 222), ('Turkmenistan', 223), ('Turks and Caicos Islands', 224), ('Tuvalu', 225), ('Uganda', 226), ('Ukraine', 227), ('United Arab Emirates', 228), ('United Kingdom', 229), ('United States Minor Outlying Islands', 230), ('United States Virgin Islands', 231), ('United States of America', 232), ('Uruguay', 233), ('Uzbekistan', 234), ('Vanuatu', 235), ('Venezuela', 236), ('Vietnam', 237), ('Wallis and Futuna', 238), ('Western Sahara', 239), ('Yemen', 240), ('Zambia', 241), ('Zimbabwe', 242)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Timestamp encoding of birthdate\n",
    "Birthdate encoded as string, i.e. \"1986-11-20\" takes 10 bytes. Encodes\n",
    "as timestamp, i.e. number of seconds since January 1st, 1970, takes 4 bytes."
   ],
   "metadata": {
    "id": "lzVfI60wz51k"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "\"\"\"\n",
    "col birthdate is string. range: 8-10. unique: 7971\n",
    "  -> Convert to timestamp  with 32bits\n",
    "\"\"\"\n",
    "df['birthdate_ts'] = df['birthdate'].apply(lambda s:  pd.to_datetime(s,format='%Y-%m-%d'))\n",
    "df['birthdate_ts'] = df['birthdate_ts'].astype(int) / 10**9\n"
   ],
   "metadata": {
    "id": "Zx9WCvOQydJ-",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:58.784667Z",
     "iopub.execute_input": "2023-10-25T22:44:58.785059Z",
     "iopub.status.idle": "2023-10-25T22:44:59.768568Z",
     "shell.execute_reply.started": "2023-10-25T22:44:58.785029Z",
     "shell.execute_reply": "2023-10-25T22:44:59.767735Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:49:09.311051800Z",
     "start_time": "2023-12-03T13:49:08.152794600Z"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Converting from datetime64[ns] to int32 is not supported. Do obj.astype('int64').astype(dtype) instead",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 7\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mcol birthdate is string. range: 8-10. unique: 7971\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03m  -> Convert to timestamp  with 32bits\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      6\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbirthdate_ts\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbirthdate\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m s:  pd\u001B[38;5;241m.\u001B[39mto_datetime(s,\u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm-\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m----> 7\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbirthdate_ts\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbirthdate_ts\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m10\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m9\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:6534\u001B[0m, in \u001B[0;36mNDFrame.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m   6530\u001B[0m     results \u001B[38;5;241m=\u001B[39m [ser\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy) \u001B[38;5;28;01mfor\u001B[39;00m _, ser \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems()]\n\u001B[0;32m   6532\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6533\u001B[0m     \u001B[38;5;66;03m# else, only a single dtype is given\u001B[39;00m\n\u001B[1;32m-> 6534\u001B[0m     new_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6535\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor_from_mgr(new_data, axes\u001B[38;5;241m=\u001B[39mnew_data\u001B[38;5;241m.\u001B[39maxes)\n\u001B[0;32m   6536\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:414\u001B[0m, in \u001B[0;36mBaseBlockManager.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    411\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m using_copy_on_write():\n\u001B[0;32m    412\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m--> 414\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    415\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mastype\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    416\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    417\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    418\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    419\u001B[0m \u001B[43m    \u001B[49m\u001B[43musing_cow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musing_copy_on_write\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    420\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:354\u001B[0m, in \u001B[0;36mBaseBlockManager.apply\u001B[1;34m(self, f, align_keys, **kwargs)\u001B[0m\n\u001B[0;32m    352\u001B[0m         applied \u001B[38;5;241m=\u001B[39m b\u001B[38;5;241m.\u001B[39mapply(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    353\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 354\u001B[0m         applied \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(b, f)(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    355\u001B[0m     result_blocks \u001B[38;5;241m=\u001B[39m extend_blocks(applied, result_blocks)\n\u001B[0;32m    357\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mfrom_blocks(result_blocks, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:616\u001B[0m, in \u001B[0;36mBlock.astype\u001B[1;34m(self, dtype, copy, errors, using_cow)\u001B[0m\n\u001B[0;32m    596\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    597\u001B[0m \u001B[38;5;124;03mCoerce to the new dtype.\u001B[39;00m\n\u001B[0;32m    598\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    612\u001B[0m \u001B[38;5;124;03mBlock\u001B[39;00m\n\u001B[0;32m    613\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    614\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m--> 616\u001B[0m new_values \u001B[38;5;241m=\u001B[39m \u001B[43mastype_array_safe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    618\u001B[0m new_values \u001B[38;5;241m=\u001B[39m maybe_coerce_values(new_values)\n\u001B[0;32m    620\u001B[0m refs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:238\u001B[0m, in \u001B[0;36mastype_array_safe\u001B[1;34m(values, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    235\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtype\u001B[38;5;241m.\u001B[39mnumpy_dtype\n\u001B[0;32m    237\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 238\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m \u001B[43mastype_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    239\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m):\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001B[39;00m\n\u001B[0;32m    241\u001B[0m     \u001B[38;5;66;03m#  trying to convert to float\u001B[39;00m\n\u001B[0;32m    242\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:180\u001B[0m, in \u001B[0;36mastype_array\u001B[1;34m(values, dtype, copy)\u001B[0m\n\u001B[0;32m    176\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m values\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(values, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m    179\u001B[0m     \u001B[38;5;66;03m# i.e. ExtensionArray\u001B[39;00m\n\u001B[1;32m--> 180\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43mvalues\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    183\u001B[0m     values \u001B[38;5;241m=\u001B[39m _astype_nansafe(values, dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:727\u001B[0m, in \u001B[0;36mDatetimeArray.astype\u001B[1;34m(self, dtype, copy)\u001B[0m\n\u001B[0;32m    725\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtype, PeriodDtype):\n\u001B[0;32m    726\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_period(freq\u001B[38;5;241m=\u001B[39mdtype\u001B[38;5;241m.\u001B[39mfreq)\n\u001B[1;32m--> 727\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdtl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDatetimeLikeArrayMixin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:477\u001B[0m, in \u001B[0;36mDatetimeLikeArrayMixin.astype\u001B[1;34m(self, dtype, copy)\u001B[0m\n\u001B[0;32m    475\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39masi8\n\u001B[0;32m    476\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mint64:\n\u001B[1;32m--> 477\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    478\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConverting from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not supported. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    479\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDo obj.astype(\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mint64\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m).astype(dtype) instead\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    480\u001B[0m     )\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy:\n\u001B[0;32m    483\u001B[0m     values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mcopy()\n",
      "\u001B[1;31mTypeError\u001B[0m: Converting from datetime64[ns] to int32 is not supported. Do obj.astype('int64').astype(dtype) instead"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df = df[['id', 'name', 'email', 'phone', 'company', 'street', 'street_number', 'zipcode', 'country_dct', 'birthdate_ts']]\n",
    "display(df)\n",
    "new_user_columns = list(df.columns.values)\n",
    "print(new_user_columns)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "xsj9CrBy4eaQ",
    "outputId": "1f762be8-d202-4be3-e180-d380f3e4b1d4",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:59.769847Z",
     "iopub.execute_input": "2023-10-25T22:44:59.771135Z",
     "iopub.status.idle": "2023-10-25T22:44:59.794335Z",
     "shell.execute_reply.started": "2023-10-25T22:44:59.771076Z",
     "shell.execute_reply": "2023-10-25T22:44:59.793450Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-12-03T13:49:09.303050400Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Varying-length binary file"
   ],
   "metadata": {
    "id": "suWjdyu7NelQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encode variable-length tuples\n"
   ],
   "metadata": {
    "id": "KUWeeBTi4XwZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#some constants for efficiency\n",
    "IDX_ID = new_user_columns.index('id')\n",
    "IDX_SN = new_user_columns.index('street_number')\n",
    "IDX_ZIP = new_user_columns.index('zipcode')\n",
    "IDX_BD = new_user_columns.index('birthdate_ts')\n",
    "IDX_COUNTRY = new_user_columns.index('country_dct')\n",
    "IDX_NAME = new_user_columns.index('name')\n",
    "IDX_EMAIL = new_user_columns.index('email')\n",
    "IDX_PHONE = new_user_columns.index('phone')\n",
    "IDX_COMPANY = new_user_columns.index('company')\n",
    "IDX_STREET = new_user_columns.index('street')\n",
    "\n",
    "def encode_var_string(s):\n",
    "  return [len(s)] + list(s.encode('ascii'))\n",
    "\n",
    "def encode_user_var_length(user, is_new_user=False):\n",
    "    '''\n",
    "    Assuming user has columns\n",
    "    ['id', 'name', 'email', 'phone', 'company', 'street', 'street_number', 'zipcode', 'country_dct', 'birthdate_ts']\n",
    "\n",
    "    encode user object:\n",
    "    id, street_number, zipcode, birthdate_ts, country_dct\n",
    "    -> to integer between 1 and 4 bytes depending on range values\n",
    "    name, email, phone, company, street\n",
    "    -> to variable-length string, e.g. \"helloworld\" -> (8,\"helloworld\") instead of using padding, e.g.\"0000000helloworld\"\n",
    "    '''\n",
    "    if not is_new_user:\n",
    "        int_list = []\n",
    "        int_list.extend(int(user[IDX_ID]).to_bytes(4,'little'))\n",
    "        int_list.extend(int(user[IDX_SN]).to_bytes(2,'little')) #max street number < 65536 (or 2^16)\n",
    "        int_list.extend(int(user[IDX_ZIP]).to_bytes(4,'little'))\n",
    "        int_list.extend(int(user[IDX_BD]).to_bytes(4,'little'))\n",
    "        int_list.extend(int(user[IDX_COUNTRY]).to_bytes(1,'little')) #max country < 256 (or 2^8)\n",
    "        int_list.extend(encode_var_string(user[IDX_NAME]))\n",
    "        int_list.extend(encode_var_string(user[IDX_EMAIL]))\n",
    "        int_list.extend(encode_var_string(user[IDX_PHONE]))\n",
    "        int_list.extend(encode_var_string(user[IDX_COMPANY]))\n",
    "        int_list.extend(encode_var_string(user[IDX_STREET]))\n",
    "        return bytearray(int_list)\n",
    "    else: # example user input: [1, 'A', 'A@m.c', '1', 'G', 'addr', 1, 2, 1, 1234567890]\n",
    "        int_list = []\n",
    "        int_list.extend(int(user[0]).to_bytes(4, 'little'))\n",
    "        int_list.extend(int(user[6]).to_bytes(2, 'little'))  # max street number < 65536 (or 2^16)\n",
    "        int_list.extend(int(user[7]).to_bytes(4, 'little'))\n",
    "        int_list.extend(int(user[9]).to_bytes(4, 'little'))\n",
    "        int_list.extend(int(user[8]).to_bytes(1, 'little'))  # max country < 256 (or 2^8)\n",
    "        int_list.extend(encode_var_string(user[1]))\n",
    "        int_list.extend(encode_var_string(user[2]))\n",
    "        int_list.extend(encode_var_string(user[3]))\n",
    "        int_list.extend(encode_var_string(user[4]))\n",
    "        int_list.extend(encode_var_string(user[5]))\n",
    "    return bytearray(int_list)"
   ],
   "metadata": {
    "id": "Ov9Vff354Xcr",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:59.795666Z",
     "iopub.execute_input": "2023-10-25T22:44:59.796850Z",
     "iopub.status.idle": "2023-10-25T22:44:59.812084Z",
     "shell.execute_reply.started": "2023-10-25T22:44:59.796816Z",
     "shell.execute_reply": "2023-10-25T22:44:59.810394Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-12-03T13:49:09.304049100Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Excercise 4: Write code to decode byte_array\n",
    "\n",
    "**Exercise 4: Complete the following code to decode a single user tuple encoded as bytes using encode_user_var_length**\n",
    "API:\n",
    "- *byte_array[start:end]* : get sub-array of bytes\n",
    "- *int.from_bytes(byte_array_slice, \"little\")*: get python integer from byte array. Note that small integer can be 1 byte, and large integer can be 4 bytes or more.\n",
    "- *str(byte_array_slice, encoding='ascii')*: get python string encoded as ascii\n"
   ],
   "metadata": {
    "id": "een6HadL4r6f"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def decode_user_var_length(byte_array):\n",
    "    '''\n",
    "    decode variable-length tuple representing user (see encode_user_var_length)\n",
    "    '''\n",
    "    id = int.from_bytes(byte_array[0:4], byteorder='little')\n",
    "    street_number = int.from_bytes(byte_array[4:6], byteorder='little')\n",
    "    zipcode = int.from_bytes(byte_array[6:10], byteorder='little')\n",
    "    bd = int.from_bytes(byte_array[10:14], byteorder='little')\n",
    "    country_dct = int.from_bytes(byte_array[14:15], byteorder='little')\n",
    "\n",
    "    name_len = int.from_bytes(byte_array[15:16], \"little\")\n",
    "    name = byte_array[16:16+name_len].decode('ascii')\n",
    "    email_len = int.from_bytes(byte_array[16+name_len:16+name_len+1], \"little\")\n",
    "    email = byte_array[16+name_len+1:16+name_len+1+email_len].decode('ascii')\n",
    "    phone_len = int.from_bytes(byte_array[16+name_len+1+email_len:16+name_len+1+email_len+1], \"little\")\n",
    "    phone = byte_array[16+name_len+1+email_len+1:16+name_len+1+email_len+1+phone_len].decode('ascii')\n",
    "    company_len = int.from_bytes(byte_array[16+name_len+1+email_len+1+phone_len:16+name_len+1+email_len+1+phone_len+1], \"little\")\n",
    "    company = byte_array[16+name_len+1+email_len+1+phone_len+1:16+name_len+1+email_len+1+phone_len+1+company_len].decode('ascii')\n",
    "    street_len = int.from_bytes(byte_array[16+name_len+1+email_len+1+phone_len+1+company_len:16+name_len+1+email_len+1+phone_len+1+company_len+1], \"little\")\n",
    "    street = byte_array[16+name_len+1+email_len+1+phone_len+1+company_len+1:16+name_len+1+email_len+1+phone_len+1+company_len+1+street_len].decode('ascii')\n",
    "    l = [id, name, email, phone, company, street, street_number, zipcode, country_dct, bd]\n",
    "\n",
    "#     loop variant, does the same, but probably a bit slower\n",
    "#     i = 0\n",
    "#     next_start = 16\n",
    "#     len_next = int.from_bytes(byte_array[15:16], \"little\")\n",
    "#     user_values = []\n",
    "#     while i < 5:\n",
    "#         start = next_start\n",
    "#         user_values.append(byte_array[start:start+len_next].decode(\"ascii\"))\n",
    "#         next_start = start+len_next+1\n",
    "#         if i != 4:\n",
    "#             len_next = int.from_bytes(byte_array[start+len_next:start+len_next+1], \"little\")\n",
    "#         i += 1\n",
    "\n",
    "#     l = [id]\n",
    "#     l.extend(user_values)\n",
    "#     l.extend([street_number, zipcode, country_dct, bd])\n",
    "\n",
    "    return l\n"
   ],
   "metadata": {
    "id": "pPZ8D_lq4XrS",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:59.814146Z",
     "iopub.execute_input": "2023-10-25T22:44:59.814685Z",
     "iopub.status.idle": "2023-10-25T22:44:59.834439Z",
     "shell.execute_reply.started": "2023-10-25T22:44:59.814643Z",
     "shell.execute_reply": "2023-10-25T22:44:59.832136Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-12-03T13:49:09.305052Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#test\n",
    "first_user = df.iloc[0]\n",
    "print(first_user.values)\n",
    "byte_array = encode_user_var_length(first_user)\n",
    "print(f'byte array len: {len(byte_array)}: {byte_array}') #107 bytes instead of 298 bytes!\n",
    "start = time.time()\n",
    "user = decode_user_var_length(byte_array)\n",
    "print(f'Decoding. Elapsed: {time.time() -start}s')\n",
    "print(f'decoded: {user}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ug6WXzv78qzY",
    "outputId": "5c40ef6e-c76f-45d1-a8ab-324cd10d074e",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:59.836571Z",
     "iopub.execute_input": "2023-10-25T22:44:59.837004Z",
     "iopub.status.idle": "2023-10-25T22:44:59.857605Z",
     "shell.execute_reply.started": "2023-10-25T22:44:59.836956Z",
     "shell.execute_reply": "2023-10-25T22:44:59.856694Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-12-03T13:49:09.306057100Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "I_d6BNoa4FnP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "## Excercise 5: Variable-length user tuples CRUD implementation"
   ],
   "metadata": {
    "id": "wOwtzQ4LgNb_",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:59.858882Z",
     "iopub.execute_input": "2023-10-25T22:44:59.859242Z",
     "iopub.status.idle": "2023-10-25T22:44:59.874236Z",
     "shell.execute_reply.started": "2023-10-25T22:44:59.859214Z",
     "shell.execute_reply": "2023-10-25T22:44:59.872825Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-12-03T13:49:09.307054Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from extendible_hashing import ExtendibleHashingIndex, BucketValue\n",
    "from typing import Union\n",
    "\n",
    "# Assume a page is 8192B\n",
    "PAGE_SIZE: int = 8192\n",
    "# There can be at most 2^13 = 8192 tuples in a page.\n",
    "TUPLE_CTR_SIZE: int = 2\n",
    "# 2B gives a max offset value of 2^13 = 8192,\n",
    "# meaning that all tuples may be 1B and will still\n",
    "# be addressable with an offset.\n",
    "OFFSET_SIZE: int = 2\n",
    "\n",
    "# An index for the user's ids in the form of a Hashtable.\n",
    "# The mapping is as follows:\n",
    "#       user_ID : bytearray(page_idx | slot_address)\n",
    "# where user_ID is the identifier in the user's id column\n",
    "# and the bytearray consists of the page's index where the\n",
    "# user tuple is stored padded to 8B and the slot_address\n",
    "# padded to 8B, which is the offset within the page to\n",
    "# the slot corresponding to the user tuple.\n",
    "user_index: ExtendibleHashingIndex = ExtendibleHashingIndex()\n",
    "remaining_page_mem_index = dict()\n",
    "\n",
    "class Page:\n",
    "    def __init__(self, page_size: int, tuple_ctr_size: int, slot_size: int):\n",
    "        \"\"\"\n",
    "        Initialize an empty page. A page has the following structure as a bytearray:\n",
    "        [page_size offset_ptr1 offset_ptr2 ... tuple_2 tuple_1]\n",
    "\n",
    "        :param page_size: The size of the page in bytes\n",
    "        :param tuple_ctr_size: The size of the page's tuple counter in bytes\n",
    "        :param slot_size: The size of an offset ptr in bytes\n",
    "        \"\"\"\n",
    "        # Page constants\n",
    "        self.page_size: int = page_size\n",
    "        self.tuple_ctr_size: int = tuple_ctr_size\n",
    "        self.slot_size: int = slot_size\n",
    "\n",
    "        # Page contents\n",
    "        # Initialized with null bytes\n",
    "        self.bytearray: bytearray = bytearray(page_size)\n",
    "\n",
    "        # Page variable members\n",
    "        # Tuples grow from back to front in the page\n",
    "        self.tuples_data_base_address: int = self.page_size\n",
    "\n",
    "    @property\n",
    "    def slot_array(self) -> bytearray:\n",
    "        \"\"\"Extract the slot array from the page. The slot\n",
    "         array contains the addresses of the tuples corresponding\n",
    "         to each slot as an offset within the page's bytearray.\n",
    "\n",
    "         The size of each slot is specified by Page.slot_size,\n",
    "         so each subsequent series of Page.slot_size bytes in\n",
    "         the return value is a single slot.\n",
    "\n",
    "        :return: A bytearray the slot array\n",
    "        \"\"\"\n",
    "        return self.bytearray[self.tuple_ctr_size: self.tuple_ctr_size + self.tuple_count * self.slot_size]\n",
    "\n",
    "    @property\n",
    "    def tuples_data(self) -> bytearray:\n",
    "        \"\"\"Extract the tuples data from the page.\n",
    "\n",
    "        :return: A bytearray containing the tuples data\n",
    "        \"\"\"\n",
    "        return self.bytearray[self.tuples_data_base_address:]\n",
    "\n",
    "    @property\n",
    "    def tuple_count(self) -> int:\n",
    "        \"\"\"Extract the current tuple count from the page bytes.\n",
    "\n",
    "        :return: The up-to-date tuple count as an int\n",
    "        \"\"\"\n",
    "        return int.from_bytes(self.bytearray[0: self.tuple_ctr_size], byteorder='little')\n",
    "\n",
    "    @property\n",
    "    def unused_memory_size(self) -> int:\n",
    "        \"\"\"Determine the amount of unused memory inside the page in bytes.\n",
    "        \n",
    "        :return: Unused memory in bytes as an int\n",
    "        \"\"\"\n",
    "        return self.tuples_data_base_address - self.tuple_ctr_size - self.tuple_count * self.slot_size\n",
    "    \n",
    "    def set_tuple_count(self, new_count: int) -> bool:\n",
    "        assert new_count >= 0, \"Cannot set a Page's tuple count to a negative value.\"\n",
    "\n",
    "        new_ctr_bytes: bytes = new_count.to_bytes(self.tuple_ctr_size, byteorder='little')\n",
    "        self.bytearray[0: self.tuple_ctr_size] = new_ctr_bytes\n",
    "\n",
    "        return True\n",
    "\n",
    "    def load_bytes(self, page_bytes: bytearray):\n",
    "        \"\"\"Load the specified bytearray into the Page instance, overwriting\n",
    "         the page's current bytearray.\n",
    "\n",
    "        Returns self to allow chaining.\n",
    "\n",
    "        :param page_bytes: The bytearray to load\n",
    "        :return: The page instance (self)\n",
    "        \"\"\"\n",
    "        assert len(page_bytes) == self.page_size, f\"Invalid data size: expected {self.page_size}B, got {len(page_bytes)}B\"\n",
    "        self.bytearray = page_bytes\n",
    "\n",
    "        self.tuples_data_base_address = self.page_size\n",
    "        if self.tuple_count > 0:\n",
    "            self.tuples_data_base_address = self.get_tuple_address(self.get_slot_address(-1))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def is_valid_slot_address(self, slot_address: int) -> bool:\n",
    "        \"\"\"Check whether the specified slot address is a valid slot address.\n",
    "\n",
    "        :param slot_address: The address to validate\n",
    "        :return: The validation result, True if valid, else False\n",
    "        \"\"\"\n",
    "        above_lower_bound: bool = slot_address >= self.tuple_ctr_size\n",
    "        below_upper_bound: bool = slot_address <= self.tuple_ctr_size + (self.tuple_count - 1) * self.slot_size\n",
    "        multiple_of_slot_size: bool = (slot_address % self.slot_size) == 0\n",
    "        return above_lower_bound and below_upper_bound and multiple_of_slot_size\n",
    "\n",
    "    def get_slot_address(self, slot_index: int) -> int:\n",
    "        \"\"\"Convert the specified slot index to the address of the corresponding\n",
    "         slot in the slot array. Negative indexes wrap around. Index zero corresponds\n",
    "         to the first slot in the array.\n",
    "\n",
    "        :param slot_index: The index of the slot to get the slot address for\n",
    "        :return: The slot address as an int\n",
    "        \"\"\"\n",
    "        # modulo on a negative int wraps around\n",
    "        bounded_index: int = slot_index % self.tuple_count\n",
    "        return self.tuple_ctr_size + bounded_index * self.slot_size\n",
    "\n",
    "    def get_tuple_address(self, slot_address: int) -> int:\n",
    "        \"\"\"Get the address of the tuple stored at the specified slot address.\n",
    "        The specified slot address is required to be a valid slot address,\n",
    "        meaning that it does not exceed the slot array's size as specified\n",
    "        by the tuple count.\n",
    "\n",
    "        :param slot_address: The slot address to extract the tuple address from\n",
    "        :return: The tuple address\n",
    "        \"\"\"\n",
    "\n",
    "        assert self.is_valid_slot_address(slot_address), \"Invalid slot address! Cannot get the tuple address.\"\n",
    "\n",
    "        tuple_address_bytes: bytearray = self.bytearray[slot_address: slot_address + self.slot_size]\n",
    "        return int.from_bytes(tuple_address_bytes, byteorder='little')\n",
    "\n",
    "    def append_tuple(self, tuple_bytes: bytearray) -> int:\n",
    "        \"\"\"\n",
    "        Append a tuple to the page. Requires the page to have enough free space.\n",
    "\n",
    "        :param tuple_bytes: The tuple bytes to append to the page\n",
    "        :return: The address of the newly stored tuple as an offset within this page\n",
    "        \"\"\"\n",
    "        assert self.data_fits(tuple_bytes), f\"Page is full, cannot write tuple bytes: {tuple_bytes}\"\n",
    "\n",
    "        # Setup\n",
    "        init_tuple_count: int = self.tuple_count\n",
    "\n",
    "        # write user to page\n",
    "        prev_tuples_base_address = self.tuples_data_base_address\n",
    "        self.tuples_data_base_address -= len(tuple_bytes)\n",
    "        self.bytearray[self.tuples_data_base_address: prev_tuples_base_address] = tuple_bytes\n",
    "\n",
    "        # write offset to page\n",
    "        new_slot_address = self.tuple_ctr_size + init_tuple_count * self.slot_size\n",
    "        self.bytearray[new_slot_address: new_slot_address + self.slot_size] =\\\n",
    "            self.tuples_data_base_address.to_bytes(self.slot_size, 'little')\n",
    "        self.set_tuple_count(init_tuple_count + 1)\n",
    "\n",
    "        return new_slot_address\n",
    "\n",
    "    def remove_tuple(self, user_id: int, page_number: int, del_user_slot_address: int) -> None:\n",
    "        \"\"\"Remove the tuple corresponding to the *del_user_slot_address* slot from the page.\n",
    "        Also updates the user_index and remaining_page_mem_index indexes.\n",
    "\n",
    "        :param user_id:\n",
    "        :param page_number: The index of the page\n",
    "        :param del_user_slot_address: The slot address corresponding to the tuple to remove\n",
    "        \"\"\"\n",
    "        from typing import List\n",
    "\n",
    "        initial_tuple_count: int = self.tuple_count\n",
    "        last_tuple_address: int = self.get_tuple_address(self.get_slot_address(-1))\n",
    "        del_user_address: int = self.get_tuple_address(del_user_slot_address)\n",
    "        del_tuple_size: int = 0\n",
    "\n",
    "        # Start of slot array\n",
    "        if del_user_slot_address == TUPLE_CTR_SIZE:\n",
    "            del_tuple_size = self.page_size - del_user_address\n",
    "        # Not start of slot array\n",
    "        else:\n",
    "            prev_slot_address: int = del_user_slot_address - self.slot_size\n",
    "            prev_tuple_address: int = self.get_tuple_address(prev_slot_address)\n",
    "            del_tuple_size = prev_tuple_address - del_user_address\n",
    "\n",
    "        to_move_tuples_amount: int = initial_tuple_count - (\n",
    "                (del_user_slot_address - self.tuple_ctr_size) // self.slot_size + 1)\n",
    "        next_slot_address: int = del_user_slot_address + self.slot_size\n",
    "        updated_slot_contents_list: List[int] = []\n",
    "\n",
    "        # update slot array contents/values in page\n",
    "        for to_move_slot_address in range(next_slot_address, next_slot_address + to_move_tuples_amount * self.slot_size,\n",
    "                                          self.slot_size):\n",
    "            original_slot_contents: int = self.get_tuple_address(to_move_slot_address)\n",
    "            updated_slot_contents: int = original_slot_contents + del_tuple_size\n",
    "            updated_slot_contents_list.append(updated_slot_contents)\n",
    "\n",
    "            updated_slot_contents_bytes: bytes = updated_slot_contents.to_bytes(self.slot_size, byteorder='little')\n",
    "            self.bytearray[to_move_slot_address - self.slot_size: to_move_slot_address] = updated_slot_contents_bytes\n",
    "\n",
    "        user_data = self.bytearray[last_tuple_address: del_user_address]\n",
    "\n",
    "        # The differences between slot contents, meaning they are the tuple lengths\n",
    "        tuple_lengths: List[int] = [\n",
    "            updated_slot_contents_list[idx] - updated_slot_contents_list[idx + 1]\n",
    "            for idx in range(0, len(updated_slot_contents_list) - 1)\n",
    "        ]\n",
    "        # The loop iterates from the leftmost tuple in the user_data,\n",
    "        # but the leftmost slot in the updated_slot_contents_list corresponds\n",
    "        # to the rightmost tuple in user data, so reverse tuple_lengths.\n",
    "        # Add random last value so that every offset is iterated on\n",
    "        tuple_lengths = tuple_lengths[::-1] + [0]\n",
    "        # The new/updated slot addresses corresponding to the moved/shifted tuples.\n",
    "        updated_slot_addresses: List[int] = \\\n",
    "            [\n",
    "                slot_address - self.slot_size\n",
    "                for slot_address in\n",
    "                range(del_user_slot_address + to_move_tuples_amount * self.slot_size, del_user_slot_address,\n",
    "                      -self.slot_size)\n",
    "            ]\n",
    "\n",
    "        progress: int = 0\n",
    "        for idx, updated_slot_address in enumerate(updated_slot_addresses):\n",
    "            tuple_len: int = tuple_lengths[idx]\n",
    "            user_id_size: int = 4\n",
    "            user_id_bytes: bytes = user_data[progress: progress + user_id_size]\n",
    "            progress += tuple_len\n",
    "\n",
    "            user_id_int: int = int.from_bytes(user_id_bytes, 'little')\n",
    "            # Slot addresses may be shorter than the space allocated to them in the index\n",
    "            padded_updated_slot_address: bytes = updated_slot_address.to_bytes(8, byteorder='little')\n",
    "            user_index.insert_keyval(user_id_int, page_number.to_bytes(8, byteorder='little') + padded_updated_slot_address)\n",
    "            # user_index[user_id_int] = page_number.to_bytes(8, byteorder='little') + padded_updated_slot_address\n",
    "\n",
    "        # Shift tuples to eliminate fragmentation due to single tuple delete\n",
    "        data_shift_address: int = last_tuple_address + del_tuple_size\n",
    "        self.bytearray[data_shift_address: data_shift_address + len(user_data)] = user_data\n",
    "        self.tuples_data_base_address += del_tuple_size\n",
    "\n",
    "        # Update tuple counter\n",
    "        self.set_tuple_count(initial_tuple_count - 1)\n",
    "\n",
    "        # update user index\n",
    "        user_index.delete(user_id)\n",
    "        # del user_index[user_id]\n",
    "\n",
    "        freed_memory: int = self.slot_size + del_tuple_size\n",
    "        remaining_page_mem_index[page_number] = remaining_page_mem_index.get(page_number, 0) + freed_memory\n",
    "\n",
    "    def data_fits(self, tuple_data: bytearray) -> bool:\n",
    "        \"\"\"\n",
    "        Whether the page contains enough free space to store the *tuple_data*.\n",
    "\n",
    "        :param tuple_data: The data to compare against available space\n",
    "        :return: True if enough space available, else False\n",
    "        \"\"\"\n",
    "        # == The space allocated to the offset pointer array\n",
    "        allocated_offsetptr_space: int = self.tuple_count * self.slot_size\n",
    "        # All page space after the offset has been allocated to tuples.\n",
    "        # == free space in page\n",
    "        free_page_space: int = self.tuples_data_base_address - (self.tuple_ctr_size + allocated_offsetptr_space)\n",
    "        # Adding a tuple requires space for the tuple and an offset ptr\n",
    "        required_tuple_space: int = len(tuple_data) + self.slot_size\n",
    "        return free_page_space >= required_tuple_space\n",
    "\n",
    "\n",
    "def create_empty_page() -> Page:\n",
    "    return Page(PAGE_SIZE, TUPLE_CTR_SIZE, OFFSET_SIZE)\n",
    "\n",
    "\n",
    "def save_users_to_binary_var_length(filename, df):\n",
    "    \"\"\"\n",
    "    saves users to fixed-length pages (our file is split up into blocks of fixed length (= pages), in this case 8192 bytes that each can contain a certain number of users)\n",
    "    we also make a bplustree with key = user id and value = page number and offset of the user in that page to be able to quickly find a user by id\n",
    "    file layout: [page1 page2 ... page_N]\n",
    "    page layout: [N offset_t1 offset_t2... offset_tN offset_tN+1 t1 t2 ... tN]\n",
    "\n",
    "    :param filename: binary file to save\n",
    "    :param df: pandas dataframe contains all users\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    from typing import List\n",
    "\n",
    "    # create pages\n",
    "    pages: List[Page] = []\n",
    "    page: Page = create_empty_page()\n",
    "    pages.append(page)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        user = encode_user_var_length(row)\n",
    "\n",
    "        if not page.data_fits(user):\n",
    "            page: Page = create_empty_page()\n",
    "            pages.append(page)\n",
    "\n",
    "        # write user to page\n",
    "        new_offset_address: int = page.append_tuple(user)\n",
    "\n",
    "        # add key = user id, value = page number and offset of user in that page to bplustree\n",
    "        user_index.insert_keyval(row['id'], (len(pages) - 1).to_bytes(8, byteorder='little') + new_offset_address.to_bytes(8, byteorder='little'))\n",
    "        # user_index[row['id']] = (len(pages) - 1).to_bytes(8, byteorder='little') + new_offset_address.to_bytes(8, byteorder='little')\n",
    "\n",
    "    # note how much free space there is left per page\n",
    "    for idx, p in enumerate(pages):\n",
    "        allocated_offsetptr_space: int = p.tuple_count * p.slot_size\n",
    "        free_page_space: int = p.tuples_data_base_address - (p.tuple_ctr_size + allocated_offsetptr_space)\n",
    "        remaining_page_mem_index[idx] = free_page_space\n",
    "\n",
    "    with open(filename, \"wb\") as f:\n",
    "        # write pages to file\n",
    "        for page in pages:\n",
    "            f.write(page.bytearray)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def load_users_from_binary_var_length(filename):\n",
    "    \"\"\"\n",
    "    load users from pages\n",
    "    page layout: [N offset_t1 offset_t2... offset_tN offset_tN+1 tN ...t2 t1]\n",
    "\n",
    "    :param filename: binary file to load\n",
    "    :return: pandas dataframe contains all users\n",
    "    \"\"\"\n",
    "\n",
    "    # extract users\n",
    "    users = []\n",
    "    with open(filename, \"rb\") as f:\n",
    "        # iterate over pages\n",
    "        page = f.read(PAGE_SIZE)\n",
    "        while page:\n",
    "            # get number of users in page\n",
    "            nr_users_in_page = int.from_bytes(page[0:TUPLE_CTR_SIZE], 'little')\n",
    "\n",
    "            # iterate over users\n",
    "            for i in range(nr_users_in_page):\n",
    "                # get offset of user\n",
    "                offset_offset = TUPLE_CTR_SIZE + i*OFFSET_SIZE\n",
    "                offset = int.from_bytes(page[offset_offset:offset_offset + OFFSET_SIZE], 'little')\n",
    "\n",
    "                user_size = 0\n",
    "                if i == 0:\n",
    "                    user_size = PAGE_SIZE - offset\n",
    "                else:\n",
    "                    prev_offset = int.from_bytes(page[offset_offset - OFFSET_SIZE:offset_offset], 'little')\n",
    "                    user_size = prev_offset - offset\n",
    "\n",
    "                # get user\n",
    "                user = page[offset:offset + user_size]\n",
    "                # decode user\n",
    "                users.append(decode_user_var_length(user))\n",
    "\n",
    "            # read next page\n",
    "            page = f.read(PAGE_SIZE)\n",
    "\n",
    "    df = pd.DataFrame(users, columns=new_user_columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_var_length_user(db_filename: str, user_id: int):\n",
    "    \"\"\"\n",
    "    Perform a random read for the user uniquely identified by the *user_id*.\n",
    "    we first find the right page, then offset and get the user.\n",
    "\n",
    "    :param db_filename: The file name of the database file\n",
    "    :param user_id: The user id of the tuple to retrieve.\n",
    "    :param user_index: bplustree index\n",
    "    :return: The user data\n",
    "    \"\"\"\n",
    "    tuple_location: bytes = bytes()\n",
    "    found: Union[BucketValue, None] = user_index.get(user_id)\n",
    "    if found is not None:\n",
    "        tuple_location = found.value\n",
    "\n",
    "    if tuple_location is None or len(tuple_location) == 0:\n",
    "        return None\n",
    "    page, offset_ptr = int.from_bytes(tuple_location[0:8], 'little'), int.from_bytes(tuple_location[8:16], 'little')\n",
    "    with open(db_filename, \"rb\") as f:\n",
    "        f.seek(page * PAGE_SIZE + offset_ptr)\n",
    "        user_size = 0\n",
    "\n",
    "        offset_in_page = f.read(TUPLE_CTR_SIZE)\n",
    "        offset_in_page_int = int.from_bytes(offset_in_page, 'little')\n",
    "        page_base_address: int = page * PAGE_SIZE\n",
    "\n",
    "        if offset_ptr == TUPLE_CTR_SIZE:\n",
    "            user_size = PAGE_SIZE - offset_in_page_int\n",
    "        else:\n",
    "            prev_offset_ptr: int = offset_ptr - OFFSET_SIZE\n",
    "\n",
    "            f.seek(page_base_address + prev_offset_ptr)\n",
    "            prev_offset_ptr = int.from_bytes(f.read(OFFSET_SIZE), 'little')\n",
    "            user_size = prev_offset_ptr - offset_in_page_int\n",
    "\n",
    "        f.seek(page_base_address + offset_in_page_int)\n",
    "        user = f.read(user_size)\n",
    "        return decode_user_var_length(user)\n",
    "\n",
    "\n",
    "def get_page_with_enough_space(db_filename: str, user_size: int):\n",
    "    \"\"\"\n",
    "    Get the page number of the page with enough space to store the user.\n",
    "\n",
    "    :param db_filename: binary file\n",
    "    :param user_size: size of user to add\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    from typing import List\n",
    "\n",
    "    # get page with enough space\n",
    "    page_number = None\n",
    "    for idx, free_space in remaining_page_mem_index.items():\n",
    "        if free_space >= user_size + OFFSET_SIZE:\n",
    "            page_number = idx\n",
    "            break\n",
    "\n",
    "    # if no page has enough space, create new page\n",
    "    if page_number is None:\n",
    "        page_number = len(remaining_page_mem_index)\n",
    "        page: Page = create_empty_page()\n",
    "        # write page to the end of the binary file\n",
    "        with open(db_filename, \"ab\") as f:\n",
    "            f.write(page.bytearray)\n",
    "        f.close()\n",
    "\n",
    "        remaining_page_mem_index[page_number] = PAGE_SIZE\n",
    "\n",
    "    return page_number\n",
    "\n",
    "\n",
    "def create_var_length_user(db_filename: str, user_tuple):\n",
    "    \"\"\"\n",
    "    Create a new user tuple in the database.\n",
    "\n",
    "    :param db_filename: binary file\n",
    "    :param user_tuple: unencoded user tuple\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # get user id\n",
    "    user_id = user_tuple[0]\n",
    "    # check if user already exists\n",
    "    assert user_index.get(user_id) is None, \"user already exists\"\n",
    "\n",
    "    # get user\n",
    "    encoded_user_tuple = encode_user_var_length(user_tuple)\n",
    "    # get user size\n",
    "    user_size = len(encoded_user_tuple)\n",
    "\n",
    "    # get page with enough space\n",
    "    page_number = get_page_with_enough_space(db_filename, user_size)\n",
    "\n",
    "    # write encoded user tuple to page\n",
    "    with open(db_filename, \"r+b\") as f:\n",
    "        # get page\n",
    "        page: Page = create_empty_page()\n",
    "        f.seek(page_number * PAGE_SIZE)\n",
    "        page.load_bytes(bytearray(f.read(page.page_size)))\n",
    "\n",
    "        # write user to page\n",
    "        new_offset_address: int = page.append_tuple(encoded_user_tuple)\n",
    "\n",
    "        # add page and user offset to user index\n",
    "        user_index.insert_keyval(user_id, page_number.to_bytes(8, 'little') + new_offset_address.to_bytes(8, 'little'))\n",
    "        # user_index[user_id] = page_number.to_bytes(8, 'little') + new_offset_address.to_bytes(8, 'little')\n",
    "\n",
    "        # write page to binary file\n",
    "        f.seek(page_number * PAGE_SIZE)\n",
    "        f.write(page.bytearray)\n",
    "\n",
    "        # update remaining page mem index\n",
    "        remaining_page_mem_index[page_number] -= user_size + OFFSET_SIZE\n",
    "\n",
    "\n",
    "def delete_var_length_user(db_filename: str, user_id):\n",
    "    \"\"\"\n",
    "    Delete a user tuple from the database.\n",
    "\n",
    "    :param db_filename: The file containing the page the user is stored in\n",
    "    :param user_id: The id column value for the user' db row\n",
    "    \"\"\"\n",
    "    # Perform index lookup\n",
    "    # tuple_location: bytes = user_index.get(user_id)\n",
    "\n",
    "    tuple_location: bytes = bytes()\n",
    "    found: Union[BucketValue, None] = user_index.get(user_id)\n",
    "    if found is not None:\n",
    "        tuple_location = found.value\n",
    "\n",
    "    if tuple_location is None or len(tuple_location) == 0:\n",
    "        return None\n",
    "    page_number: int = int.from_bytes(tuple_location[0:8], 'little')\n",
    "    del_user_slot_address: int = int.from_bytes(tuple_location[8:16], 'little')\n",
    "\n",
    "    with open(db_filename, \"r+b\") as f:\n",
    "        # Setup page\n",
    "        page: Page = create_empty_page()\n",
    "        f.seek(page_number * PAGE_SIZE)\n",
    "        page.load_bytes(bytearray(f.read(page.page_size)))\n",
    "\n",
    "        page.remove_tuple(user_id, page_number, del_user_slot_address)\n",
    "\n",
    "        # Actually write page to memory\n",
    "        f.seek(page_number * PAGE_SIZE)\n",
    "        f.write(page.bytearray)\n",
    "\n",
    "\n",
    "def update_var_length_user(db_filename: str, user_id, updated_user_tuple):\n",
    "    \"\"\"\n",
    "    Update a user tuple in the database.\n",
    "\n",
    "    :param db_filename: binary file\n",
    "    :param user_id: user id of the user to update\n",
    "    :param updated_user_tuple: unencoded user tuple\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Perform index lookup\n",
    "    # tuple_location: bytes = user_index.get(user_id)\n",
    "\n",
    "    tuple_location: bytes = bytes()\n",
    "    found: Union[BucketValue, None] = user_index.get(user_id)\n",
    "    if found is not None:\n",
    "        tuple_location = found.value\n",
    "\n",
    "    if tuple_location is None or len(tuple_location) == 0:\n",
    "        return None\n",
    "    page_number: int = int.from_bytes(tuple_location[0:8], 'little')\n",
    "    update_user_slot_address: int = int.from_bytes(tuple_location[8:16], 'little')\n",
    "    final_page_number: int = -1\n",
    "\n",
    "    encoded_updated_user_tuple = encode_user_var_length(updated_user_tuple)\n",
    "    updated_user_tuple_size = len(encoded_updated_user_tuple)\n",
    "\n",
    "    with open(db_filename, \"r+b\") as f:\n",
    "        # Setup page\n",
    "        page: Page = create_empty_page()\n",
    "        f.seek(page_number * page.page_size)\n",
    "        page.load_bytes(bytearray(f.read(page.page_size)))\n",
    "\n",
    "        # Setup vars\n",
    "        updated_user_address: int = page.get_tuple_address(update_user_slot_address)\n",
    "        old_user_tuple_size: int = 0\n",
    "\n",
    "        # Start of slot array\n",
    "        if update_user_slot_address == TUPLE_CTR_SIZE:\n",
    "            old_user_tuple_size = PAGE_SIZE - updated_user_address\n",
    "        # Not start of slot array\n",
    "        else:\n",
    "            prev_slot_address: int = update_user_slot_address - page.slot_size\n",
    "            prev_tuple_address: int = page.get_tuple_address(prev_slot_address)\n",
    "            old_user_tuple_size = prev_tuple_address - updated_user_address\n",
    "\n",
    "        # first check if there is enough space for the updated user tuple in the page if we would replace the old one\n",
    "        if remaining_page_mem_index.get(page_number, 0) < updated_user_tuple_size - old_user_tuple_size:\n",
    "            # not enough space\n",
    "            # delete old user tuple from page\n",
    "            page.remove_tuple(user_id, page_number, update_user_slot_address)\n",
    "            # Actually write page to memory\n",
    "            f.seek(page_number * PAGE_SIZE)\n",
    "            f.write(page.bytearray)\n",
    "\n",
    "            # find the next page with enough space\n",
    "            other_page_number: int = get_page_with_enough_space(db_filename, updated_user_tuple_size)\n",
    "            final_page_number = other_page_number\n",
    "\n",
    "            # get page\n",
    "            page: Page = create_empty_page()\n",
    "            f.seek(other_page_number * PAGE_SIZE)\n",
    "            page.load_bytes(bytearray(f.read(page.page_size)))\n",
    "\n",
    "        else:\n",
    "            # TODO scuffed but easy: just remove tuple and re-append\n",
    "            # enough space, we can just write the user tuple to the page\n",
    "            # Remove old user tuple\n",
    "            page.remove_tuple(user_id, page_number, update_user_slot_address)\n",
    "            final_page_number = page_number\n",
    "\n",
    "        # write user to page\n",
    "        new_offset_address: int = page.append_tuple(encoded_updated_user_tuple)\n",
    "\n",
    "        # add page and user offset to user index\n",
    "        user_index.insert_keyval(user_id, final_page_number.to_bytes(8, 'little') + new_offset_address.to_bytes(8, 'little'))\n",
    "        # user_index[user_id] = final_page_number.to_bytes(8, 'little') + new_offset_address.to_bytes(8, 'little')\n",
    "\n",
    "        # update remaining page mem index\n",
    "        remaining_page_mem_index[final_page_number] -= updated_user_tuple_size + OFFSET_SIZE\n",
    "\n",
    "        # write page to binary file\n",
    "        f.seek(final_page_number * PAGE_SIZE)\n",
    "        f.write(page.bytearray)\n",
    "\n",
    "    print(\"userID \", user_id, \" from page \", page_number, \" to page \", final_page_number)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:59.876895Z",
     "iopub.execute_input": "2023-10-25T22:44:59.877278Z",
     "iopub.status.idle": "2023-10-25T22:44:59.938949Z",
     "shell.execute_reply.started": "2023-10-25T22:44:59.877246Z",
     "shell.execute_reply": "2023-10-25T22:44:59.937766Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-12-03T13:49:09.308054600Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#save\n",
    "fname_bin = 'fake_users.bin2'\n",
    "save_users_to_binary_var_length(fname_bin, df)\n",
    "file_size = os.stat(fname_bin).st_size\n",
    "print(f\"File size is {file_size}B\") #was 2980000B, know 999927B (about 33% of fixed-length)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "omSSmasHoR86",
    "outputId": "4c0859b4-d5e6-4c1f-bb8f-56ede8069360",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:44:59.940789Z",
     "iopub.execute_input": "2023-10-25T22:44:59.941498Z",
     "iopub.status.idle": "2023-10-25T22:45:00.954621Z",
     "shell.execute_reply.started": "2023-10-25T22:44:59.941456Z",
     "shell.execute_reply": "2023-10-25T22:45:00.953280Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-12-03T13:49:09.309052500Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#load\n",
    "df3 = load_users_from_binary_var_length(fname_bin)\n",
    "display(df3)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "sd80QRHEq1SX",
    "outputId": "3eaa749e-4481-4a12-c0fe-12ae506f5ece",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:45:00.956219Z",
     "iopub.execute_input": "2023-10-25T22:45:00.956781Z",
     "iopub.status.idle": "2023-10-25T22:45:01.078614Z",
     "shell.execute_reply.started": "2023-10-25T22:45:00.956750Z",
     "shell.execute_reply": "2023-10-25T22:45:01.076655Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-12-03T13:49:09.310049300Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def test_code():\n",
    "    user_index = dict()\n",
    "    dft = pd.DataFrame(\n",
    "    columns=['id', 'name', 'email', 'phone', 'company', 'street', 'street_number', 'zipcode', 'country_dct',\n",
    "             'birthdate_ts'])\n",
    "    # Reduce page size for easier testing\n",
    "    global PAGE_SIZE\n",
    "    OLD_PAGE_SIZE = PAGE_SIZE\n",
    "    PAGE_SIZE = 256\n",
    "\n",
    "    \"\"\"Simple test code that was manually modified configured to check for specific bugs.\n",
    "    This test code does NOT cover all cases and is mainly oriented towards small scale,\n",
    "    manual verification of expected results.\n",
    "    \"\"\"\n",
    "    print(\"\"\"\n",
    "#########################\n",
    "# CREATE TEST DATAFRAME #\n",
    "#########################\n",
    "\"\"\", flush=True)\n",
    "    # make a dataframe with a few users with random data with columns: id, name, email, phone, company, street, street_number, zipcode, country_dct, birthdate_ts, initialize with array\n",
    "    dft.loc[0] = [1, 'John Doe', 'johndoe@gmail.com', '1234567890', 'Google', '1600 Amphitheatre Parkway', 1600, 94043,\n",
    "                 1, 1234567890]\n",
    "    dft.loc[1] = [2, 'Johnny Smith', 'johnsmith@gmail.com', '1234567890', 'Google', '1600 Amphitheatre Parkway', 1600,\n",
    "                 94043, 1, 1234567890]\n",
    "    dft.loc[2] = [3, 'Bill Doe', 'billdoe@gmail.com', '1234567890', 'Google', '1600 Amphitheatre Parkway', 1600, 94043,\n",
    "                 1, 1234567890]\n",
    "    dft.loc[3] = [4, 'Jane Doe', 'janedoe@gmail.com', '1234567890', 'Google', '1600 Amphitheatre Parkway', 1600, 94043,\n",
    "                 1, 1234567890]\n",
    "\n",
    "    dft.loc[0] = [1, 'A', 'A@m.c', '1', 'G', 'addr', 1, 2, 1, 1234567890]\n",
    "    dft.loc[1] = [2, 'B', 'B@m.c', '12', 'G', 'addr', 1, 2, 1, 1234567890]\n",
    "    dft.loc[2] = [3, 'C', 'C@m.c', '123', 'G', 'addr', 1, 2, 1, 1234567890]\n",
    "    dft.loc[3] = [4, 'D', 'D@m.c', '1234', 'G', 'addr', 1, 2, 1, 1234567890]\n",
    "    dft.loc[4] = [5, 'E', 'E@m.c', '12345', 'G', 'addr', 1, 2, 1, 1234567890]\n",
    "\n",
    "    for uid in range(97 + 5, 97 + 26):\n",
    "        dft.loc[uid] = [uid, chr(uid), chr(uid) + '@m.c', '12345', 'G', 'addr', 1, 2, 1, 1234567890]\n",
    "\n",
    "    save_users_to_binary_var_length(\"test.bin\", dft)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print(user_index.get(1))\n",
    "    # print(user_index.get(2))\n",
    "    # print(user_index.get(3))\n",
    "    # print(user_index.get(4))\n",
    "    # print(int.from_bytes(user_index.get(1)[0:8], 'little'), int.from_bytes(user_index.get(1)[8:16], 'little'))\n",
    "    # print(int.from_bytes(user_index.get(2)[0:8], 'little'), int.from_bytes(user_index.get(2)[8:16], 'little'))\n",
    "    # print(int.from_bytes(user_index.get(3)[0:8], 'little'), int.from_bytes(user_index.get(3)[8:16], 'little'))\n",
    "    # print(int.from_bytes(user_index.get(4)[0:8], 'little'), int.from_bytes(user_index.get(4)[8:16], 'little'))\n",
    "    # print(\"\\n\")\n",
    "\n",
    "    print(\"\"\"\n",
    "#############################\n",
    "# DISPLAY INITIAL DATAFRAME #\n",
    "#############################\n",
    "\"\"\", flush=True)\n",
    "\n",
    "    df4 = load_users_from_binary_var_length(\"test.bin\")\n",
    "    display(df4)\n",
    "\n",
    "    print(\"\"\"\n",
    "##############\n",
    "# READ USERS #\n",
    "##############\n",
    "\"\"\", flush=True)\n",
    "\n",
    "    #Read 4 random users\n",
    "    print(\"------ BEFORE DELETE ------\")\n",
    "    random_ids = [1, 2, 3, 4, 5]\n",
    "    random_users = []\n",
    "    for id in random_ids:\n",
    "        user_i = read_var_length_user(\"test.bin\", id)\n",
    "        random_users.append(user_i)\n",
    "    df_sample4 = pd.DataFrame(random_users, columns=new_user_columns)\n",
    "    display(df_sample4)\n",
    "\n",
    "    print(\"\"\"\n",
    "################\n",
    "# DELETE USERS #\n",
    "################\n",
    "\"\"\", flush=True)\n",
    "\n",
    "    delete_var_length_user(\"test.bin\", 3)\n",
    "    delete_var_length_user(\"test.bin\", 1)\n",
    "    delete_var_length_user(\"test.bin\", 5)\n",
    "    delete_var_length_user(\"test.bin\", 4)\n",
    "\n",
    "\n",
    "    #Read 4 random users\n",
    "    print(\"------ AFTER DELETE ------\")\n",
    "    random_ids = [1, 2, 3, 4, 5]\n",
    "    random_users = []\n",
    "    for id in random_ids:\n",
    "        user_i = read_var_length_user(\"test.bin\", id)\n",
    "        if user_i is None:\n",
    "            continue\n",
    "        random_users.append(user_i)\n",
    "    df_sample2 = load_users_from_binary_var_length(\"test.bin\")\n",
    "    display(df_sample2)\n",
    "\n",
    "    print(\"\"\"\n",
    "################\n",
    "# CREATE USERS #\n",
    "################\n",
    "\"\"\", flush=True)\n",
    "\n",
    "    # create new user\n",
    "    new_user = [1000, 'A', 'A@m.c', '1', 'G', 'addr', 1, 2, 1, 1234567890]\n",
    "    new_user2 = [2000, 'G', 'G@m.c', '1', 'G', 'addr', 1, 2, 1, 1234567890]\n",
    "    for uid in range(10000, 10000 + 1000):\n",
    "        new_userx = [uid, str(uid), 'G@m.c', '1', 'G', 'addr', 1, 2, 1, 1234567890]\n",
    "        create_var_length_user(\"test.bin\", new_userx)\n",
    "    create_var_length_user(\"test.bin\", new_user)\n",
    "    create_var_length_user(\"test.bin\", new_user2)\n",
    "    df4 = load_users_from_binary_var_length(\"test.bin\")\n",
    "    display(df4)\n",
    "\n",
    "    print(\"\"\"\n",
    "################\n",
    "# UPDATE USERS #\n",
    "################\n",
    "\"\"\", flush=True)\n",
    "\n",
    "    # update user\n",
    "    for new_user_id in range(105, 115):\n",
    "        new_user = [new_user_id, str(new_user_id), str(new_user_id) * 5 + '@m.c', '3', 'H', 'addr', 1, 2, 1, 1333566890]\n",
    "        update_var_length_user(\"test.bin\", new_user_id, new_user)\n",
    "\n",
    "    df4 = load_users_from_binary_var_length(\"test.bin\")\n",
    "    display(df4)\n",
    "\n",
    "    # Reinstate page size\n",
    "    PAGE_SIZE = OLD_PAGE_SIZE\n",
    "    df4.iloc[0:0]\n",
    "    dft.iloc[0:0]\n",
    "    df_sample4.iloc[0:0]\n",
    "    df_sample2.iloc[0:0]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-25T22:45:01.081102Z",
     "iopub.execute_input": "2023-10-25T22:45:01.082624Z",
     "iopub.status.idle": "2023-10-25T22:45:01.101903Z",
     "shell.execute_reply.started": "2023-10-25T22:45:01.082574Z",
     "shell.execute_reply": "2023-10-25T22:45:01.100694Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-12-03T13:49:09.311051800Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_code()"
   ],
   "metadata": {
    "id": "Ag5KiRM9NelR",
    "execution": {
     "iopub.status.busy": "2023-10-25T22:45:01.106085Z",
     "iopub.execute_input": "2023-10-25T22:45:01.106620Z",
     "iopub.status.idle": "2023-10-25T22:45:01.254095Z",
     "shell.execute_reply.started": "2023-10-25T22:45:01.106587Z",
     "shell.execute_reply": "2023-10-25T22:45:01.252057Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-12-03T13:49:09.312052300Z"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
